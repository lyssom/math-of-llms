---
layout: page
title: 1.1 线性代数与张量运算
mathjax: true
---

### 1.1.1 线性代数的核心地位

线性代数作为现代数学的重要分支，在大语言模型的理论基础中占据着不可替代的核心地位。从Transformer架构的注意力机制到词嵌入的向量表示，从矩阵乘法的并行计算到张量运算的维度变换，线性代数为理解和构建深度学习模型提供了坚实的数学框架。大语言模型中的所有参数最终都以矩阵或张量的形式存储和计算，因此深入掌握线性代数的基本概念和运算规则是理解模型工作原理的必要前提。

在线性代数的学习路径中，我们需要首先明确几个基本定义。向量是线性空间中最基本的元素，可以理解为一维数组中的有序数集。在大语言模型的语境下，词向量就是典型的向量表示，每个词被映射为一个高维实数向量，这个向量的每一个维度都编码了某种语义或语法特征。例如，一个300维的词向量可以看作是一个从自然语言到连续向量空间的映射，将离散的符号表示转化为连续的数值表示，从而使得机器学习算法能够在这些向量上进行运算和优化。

矩阵是二维数组，是线性代数中最重要的研究对象之一。在大语言模型中，权重矩阵无处不在：嵌入层将词汇映射为向量，实际上是一个巨大的查找矩阵；注意力机制中的查询、键、值投影都是通过矩阵乘法实现的；前馈神经网络中的全连接层更是由多个权重矩阵堆叠而成。矩阵的形状（行数和列数）决定了它所代表的线性变换的类型，也决定了它在网络中的具体作用方式。

张量是多维数组的自然推广，是矩阵概念在更高维度的延伸。一阶张量是向量，二阶张量是矩阵，三阶及更高阶的张量则可以表示更复杂的数据结构。在现代深度学习框架中，如PyTorch和TensorFlow中，张量是最基本的数据结构，几乎所有的计算都在张量之上进行。大语言模型中的输入通常是一个三维张量，其维度分别代表批量大小、序列长度和嵌入维度。通过张量运算，模型能够高效地并行处理大量数据，这也是大语言模型能够实现高效训练和推理的关键技术基础。

### 1.1.2 基本运算与运算规则

线性代数的基本运算包括向量加法、标量乘法、矩阵乘法、转置和求逆等。这些运算在大语言模型中有着直接的应用场景，理解它们的数学性质和计算特性对于优化模型性能和调试模型行为至关重要。

向量加法是逐分量（component-wise）的运算，两个维度相同的向量可以逐分量相加。设有两个$n$维向量 $\mathbf{u} = (u_1, \ldots, u_n)$和$\mathbf{v} = (v_1, \ldots, v_n)$，则其和为
$$
\mathbf{u} + \mathbf{v} = (u_1 + v_1, \ldots, u_n + v_n)
$$
向量加法满足交换律和结合律。

在大语言模型（如 Transformer）中，残差连接是向量加法的典型应用。它将某一子层的输入与该子层的输出直接相加，从而在反向传播时为梯度提供了一条恒等映射路径，使梯度能够绕过复杂的非线性变换直接传播到较浅层，显著提升了深层模型的可训练性，并有效缓解梯度消失问题。

标量乘法是将一个向量与一个标量（实数）相乘，结果是将向量的每个分量都乘以该标量。这种运算在模型的权重初始化、学习率调整和梯度裁剪中都有应用。例如，梯度裁剪就是将梯度向量的模长限制在某个阈值之内，具体做法是如果梯度的范数超过阈值，就将梯度向量乘以一个缩放因子使其范数等于阈值。

矩阵乘法是最重要也是计算量最大的运算。两个矩阵$\mathbf{A} \in \mathbb{R}^{m \times n}$和$\mathbf{B} \in \mathbb{R}^{n \times p}$的乘积$\mathbf{C} = \mathbf{AB}$ 是一个$m \times p$的矩阵，其中每个元素$c_{ij} = \sum_{k=1}^{n} a_{ik} b_{kj}$。矩阵乘法满足结合律$(\mathbf{AB})\mathbf{C} = \mathbf{A}(\mathbf{BC})$ 和分配律$\mathbf{A}(\mathbf{B} + \mathbf{C}) = \mathbf{AB} + \mathbf{AC}$，但不满足交换律，即$\mathbf{AB}$通常不等于$\mathbf{BA}$。在大语言模型中，注意力机制的计算过程就包含了多个矩阵乘法操作：查询矩阵与键矩阵的乘积产生注意力分数，注意力权重与值矩阵的乘积产生加权输出。这些矩阵乘法的计算效率直接影响模型的整体性能，因此现代GPU都针对矩阵运算进行了专门的硬件优化。

矩阵的转置是将矩阵的行和列互换，记作$\mathbf{A}^\top$或$\mathbf{A}^T$。转置运算满足$(\mathbf{A}^\top)^\top = \mathbf{A}$和$(\mathbf{AB})^\top = \mathbf{B}^\top \mathbf{A}^\top(AB)$。在大语言模型中，自注意力机制需要计算查询向量与键向量的相似度，这本质上就是计算查询矩阵与转置后的键矩阵的乘积。此外，在实现反向传播时，转置操作也经常用于梯度的反向传播计算。

矩阵的求逆是找到一个矩阵$\mathbf{A}^{-1}$使得$\mathbf{A}\mathbf{A}^{-1} = \mathbf{A}^{-1}\mathbf{A} = \mathbf{I}$，其中$\mathbf{I}$是单位矩阵。只有方阵才可能存在逆矩阵，而且并非所有方阵都有逆矩阵——只有满秩（行列式非零）的方阵才是可逆的。在深度学习中，我们很少直接计算矩阵的逆，因为数值稳定性较差且计算成本高昂。但矩阵求逆的数学思想——通过逆运算解线性方程组——在优化算法和正则化方法中有着重要的应用。例如，线性回归的闭式解就是通过求解正规方程得到的，而正规方程的求解等价于计算矩阵的伪逆。

### 1.1.3 张量的表示与运算

张量是多维数组在数学上的抽象表示，它将标量（零阶张量）、向量（一阶张量）和矩阵（二阶张量）的概念推广到任意维度。一个$k$阶张量有$k$个索引，每个索引对应张量的一个维度。设有一个三阶张量$\mathcal{X} \in \mathbb{R}^{I \times J \times K}$，则其元素可以表示为$x_{ijk}$​，其中$1 \leq i \leq I$，$1 \leq j \leq J$，$1 \leq k \leq K$。

在大语言模型的实践中，张量的维度通常具有明确的语义含义。以Transformer模型为例，输入张量的形状通常是 $(B,S,D)$，其中$B$是批量大小（batch size），$S$是序列长度（sequence length），$D$是隐藏维度（hidden dimension）。在多头注意力中，经过线性投影并拆分注意力头后，张量可重排为$(B,H,S,D/H)$的张量，其中$H$是注意力头的数量。经过注意力计算后的输出张量会与输入张量形状相同，便于进行残差连接和层归一化操作。
![[llm_flow.drawio.png]]
张量运算的基本操作包括逐元素运算、重塑（reshape）、转置（transpose）、广播（broadcasting）和张量收缩（contraction）等。逐元素运算对张量中的每个独立元素应用相同的函数，如ReLU激活函数$f(x) = \max(0, x)$就是典型的逐元素运算。重塑操作改变张量的形状但不改变其包含的数据元素，例如将一个$(B, S \cdot D)$的二维张量重塑为$(B,S,D)$的三维张量，这在将展平后的向量恢复为嵌入序列时非常有用。

广播是张量逐元素运算中的一种自动对齐机制。当两个形状不同的张量进行逐元素运算时，深度学习框架会在不显式复制数据的情况下，将形状较小的张量在某些维度上**视为被重复**，以匹配较大的张量。广播规则通常是从最后一个维度开始逐维比较：如果对应维度相等，或其中一个维度为 1，则该维度可以广播；否则形状不兼容。若两个张量的维度数不同，则会在较小张量的左侧自动补 1。  NumPy、PyTorch 等现代深度学习框架均支持广播机制，它可以显著简化代码（例如 bias 加法），但由于广播可能在语法上合法而在语义上错误，不当使用容易引入隐蔽且难以察觉的 bug。

张量收缩是矩阵乘法在高维张量上的推广，又称为张量点积或广义矩阵乘法。张量收缩指定两个张量的若干维度进行配对相乘并求和。例如，两个三阶张量$\mathcal{A} \in \mathbb{R}^{I \times J \times K}$和$\mathcal{B} \in \mathbb{R}^{J \times K \times L}$在第二和第三维度上的收缩产生一个$I \times L$的矩阵。在注意力机制中，注意力分数的计算可以看作是一个张量收缩操作，其中查询向量与键向量在特征维度上进行点积运算。

张量分解是处理高维张量的重要技术。常见的张量分解方法包括 **CP 分解（CANDECOMP/PARAFAC）** 和 **Tucker 分解**。CP 分解将一个张量表示为若干个秩一张量的和，而 Tucker 分解则将张量表示为一个核心张量与多个因子矩阵在各模上的乘积。张量分解在模型压缩、参数高效微调以及模型蒸馏等场景中具有重要应用，通过将大型权重张量分解为若干低秩张量，可以在保持模型性能的同时显著减少参数量和计算开销。


### 1.1.4 特征空间的几何直觉

特征空间是机器学习和深度学习中描述数据表示的核心概念。从几何角度来看，一个n维特征空间可以理解为一个n维欧几里得空间$\mathbb{R}^n$，空间中的每个点代表一个数据样本在该空间中的表示。在大语言模型中，词嵌入空间就是一个典型的高维特征空间，其中每个词被映射为空间中的一个点，语义相近的词在空间中距离较近，语义不同的词则距离较远。这种几何表示使得我们可以利用空间中的几何关系来理解和操作语义信息。

词嵌入空间具有一些重要的几何性质。首先，嵌入空间通常是密集的，这意味着每个维度都不是二元的或稀疏的，而是取连续的实数值。这种密集表示使得模型能够在连续空间中学习平滑的语义关系。其次，嵌入空间的维度通常远小于词表大小，但又足够高以捕获丰富的语义信息。维度的选择是一个重要的超参数，过低的维度可能导致表达能力的损失（称为欠拟合），过高的维度则可能导致过拟合和计算效率的下降。

向量距离和相似度是度量特征空间中样本关系的基本工具。欧几里得距离$d(\mathbf{u}, \mathbf{v}) = \|\mathbf{u} - \mathbf{v}\|_2$测量两个向量之间的直线距离。余弦相似度$\text{cosine}(\mathbf{u}, \mathbf{v}) = \frac{\mathbf{u} \cdot \mathbf{v}}{\|\mathbf{u}\|_2 \|\mathbf{v}\|_2}$测量两个向量方向的相似程度，与向量的大小无关。在词嵌入研究中，余弦相似度是最常用的相似度度量，因为它能够捕捉语义方向的相似性而不受词频等因素的影响。

线性变换是理解特征空间中数据变换的关键概念。一个线性变换$T: \mathbb{R}^n \to \mathbb{R}^m$可以用一个矩阵 $\mathbf{A} \in \mathbb{R}^{m \times n}$表示，满足$T(\mathbf{u} + \mathbf{v}) = T(\mathbf{u}) + T(\mathbf{v})$和 $T(c\mathbf{u}) = cT(\mathbf{u})$。线性变换对特征空间的作用包括旋转、缩放、投影和剪切等。旋转保持向量的模长不变，只改变方向；缩放改变向量的模长；投影将向量映射到低维子空间；剪切则是一种保持体积但改变形状的变换。在神经网络中，全连接层就是典型的线性变换加上非线性激活函数的组合。

子空间是特征空间中的重要结构。一个k维子空间是特征空间的一个k维线性子集，包含所有可以通过原点的k维平面上的点。列空间（Column Space）是矩阵所有列向量的线性组合构成的空间，它描述了矩阵所能表示的所有输出。零空间（Null Space）是所有被矩阵映射到零向量的输入向量构成的空间，它描述了输入中的冗余信息。在大语言模型中，权重矩阵的列空间决定了该层能够表示的特征空间的范围，而零空间则包含了可能被"遗忘"的信息。

### 1.1.5 特征值与特征向量

特征值和特征向量是线性代数中最深刻也最有应用价值的概念之一。它们揭示了线性变换的本质特征：某些特定方向（特征向量）在变换下只发生缩放而不改变方向，缩放的倍数就是特征值。数学上，给定一个方阵$\mathbf{A} \in \mathbb{R}^{n \times n}$，如果存在非零向量$\mathbf{v} \in \mathbb{R}^n$和标量$\lambda \in \mathbb{R}$满足$\mathbf{A}\mathbf{v} = \lambda\mathbf{v}$，则称$\mathbf{v}$是$\mathbf{A}$的特征向量，$\lambda$是对应的特征值。

特征值的计算需要求解特征方程$\det(\mathbf{A} - \lambda\mathbf{I}) = 0$，这是一个关于$\lambda$的多项式方程。对于大型矩阵，直接求解特征方程通常是不切实际的，因为在数值上计算高阶多项式的根非常困难。在实践中，我们使用迭代算法如幂迭代（Power Iteration）、反幂迭代（Inverse Iteration）和QR算法来计算特征值和特征向量。深度学习框架也提供了高效的函数来计算矩阵的特征值分解和奇异值分解。

在大语言模型中，特征值和特征向量有着多方面的应用。首先，在主成分分析（PCA）中，特征值分解用于提取数据中方差最大的方向，这些方向称为主成分。通过保留最大的k个特征值对应的特征向量，我们可以实现降维同时最小化信息损失。词嵌入的降维可视化（如t-SNE和UMAP）就依赖于这种思想，先通过PCA进行初步降维，再用非线性方法进行二维或三维嵌入。
![[pca.drawio.png]]
其次，特征值与网络稳定性密切相关。一个线性 dynamical system $\dot{\mathbf{x}} = \mathbf{A}\mathbf{x}$的稳定性由矩阵$\mathbf{A}$的特征值决定：如果所有特征值的实部都为负，则系统是稳定的；如果有特征值的实部为正，则系统是不稳定的。在循环神经网络（RNN）和Transformer中，类似的稳定性分析有助于理解和解决梯度消失或梯度爆炸问题。例如，LSTM和GRU通过门控机制设计，使得等效的变换矩阵具有接近1的特征值，从而缓解了梯度消失问题。

第三，谱范数（Spectral Norm）是矩阵的最大奇异值，等于矩阵$\mathbf{A}^\top \mathbf{A}$的最大特征值的平方根。谱范数在深度学习中有重要应用：它用于权重归一化以稳定训练过程，也是证明神经网络泛化性质的关键工具。谱归一化（Spectral Normalization）是一种常用的权重归一化技术，它将权重矩阵的谱范数归一化为1，从而约束了网络函数的Lipschitz常数，这对训练生成对抗网络（GAN）和防止对抗攻击都很重要。

### 1.1.6 奇异值与低秩近似

奇异值分解（Singular Value Decomposition，SVD）是将任意矩阵分解为三个矩阵乘积的强大工具，被誉为"线性代数的瑞士军刀"。对于任意矩阵$\mathbf{A} \in \mathbb{R}^{m \times n}$，存在正交矩阵$\mathbf{U} \in \mathbb{R}^{m \times m}$、$\mathbf{V} \in \mathbb{R}^{n \times n}$和对角矩阵$\mathbf{\Sigma} \in \mathbb{R}^{m \times n}$，使得$\mathbf{A} = \mathbf{U}\mathbf{\Sigma}\mathbf{V}^\top$。其中，$\mathbf{\Sigma}$的对角线元素$\sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_r > 0$（r为矩阵的秩）称为奇异值，是$\mathbf{A}^\top \mathbf{A}$的特征值的平方根。$\mathbf{U}$的列向量称为左奇异向量，$\mathbf{V}$的列向量称为右奇异向量。

奇异值分解与特征值分解有密切关系，但又有所不同。特征值分解只适用于方阵且要求矩阵可对角化，而奇异值分解适用于任意矩阵。另外，特征值可以是负数（对于实对称矩阵，特征值是实数），但奇异值总是非负的。奇异值分解之所以强大，正是因为它对任何矩阵都成立，无论是方阵还是矩形阵，无论是否满秩。

低秩近似是奇异值分解最重要的应用之一。根据Eckart-Young-Mirsky定理，对于任何整数$k \leq r$，用秩不超过k的矩阵对$\mathbf{A}$的最佳近似（在Frobenius范数和谱范数意义下）就是保留前k个最大的奇异值及其对应的奇异向量，即$\mathbf{A}_k = \sum_{i=1}^{k} \sigma_i \mathbf{u}_i \mathbf{v}_i^\top$。这个近似将原始矩阵分解为k个秩一矩阵的和，每个秩一矩阵对应一个主成分方向。

在大语言模型中，低秩近似技术有着广泛的应用。首先，在模型压缩方面，权重矩阵的低秩近似可以显著减少参数量和计算量。假设一个$m \times n$的权重矩阵被近似为$\mathbf{A} \approx \mathbf{U}_k \mathbf{V}_k^\top$​，其中$\mathbf{U}_k \in \mathbb{R}^{m \times k}$，$\mathbf{V}_k \in \mathbb{R}^{n \times k}$，则参数量从$mn$减少到$k(m+n)$。当$k \ll \min(m,n)$时，这种压缩是显著的。

其次，在参数高效微调（Parameter-Efficient Fine-Tuning，PEFT）中，低秩更新是一种核心技术。典型的低秩适配方法如LoRA（Low-Rank Adaptation）假设预训练模型的权重更新可以表示为低秩矩阵，即$\Delta \mathbf{W} = \mathbf{B}\mathbf{A}$，其中$\mathbf{A} \in \mathbb{R}^{k \times n}$，$\mathbf{B} \in \mathbb{R}^{m \times k}$。这样，只需要训练$k(m+n)$个参数而不是$mn$个参数，就可以实现对大型语言模型的有效微调。这种方法的数学基础正是低秩近似理论。

第三，奇异值分解可以用于理解模型的表达能力。通过分析权重矩阵的奇异值分布，我们可以了解模型使用了多少"有效自由度"。如果只有少数几个奇异值很大，说明模型的表达能力主要集中在少数方向上；如果奇异值分布比较均匀，则模型利用了更多的参数自由度。这种分析对于诊断模型过拟合和理解模型容量都很有价值。

### 1.1.7 正交性与正交矩阵

正交性是线性代数中一个核心概念，具有重要的几何意义和计算优势。两个向量$\mathbf{u}$和$\mathbf{v}$如果满足$\mathbf{u}^\top \mathbf{v} = 0$，则称它们是正交的。一组向量如果两两正交且都是单位向量，则称为标准正交基。正交矩阵是满足$\mathbf{Q}^\top \mathbf{Q} = \mathbf{Q}\mathbf{Q}^\top = \mathbf{I}$的方阵$\mathbf{Q}$，其列向量（或行向量）构成标准正交基。

正交矩阵有几个重要的性质。首先，正交矩阵保持向量的范数不变，即$\|\mathbf{Q}\mathbf{x}\|_2 = \|\mathbf{x}\|_2$对所有向量$\mathbf{x}$成立。这意味着正交变换是一种保距变换，它只旋转或反射空间而不改变向量的长度。其次，正交矩阵的逆矩阵等于其转置矩阵，即$\mathbf{Q}^{-1} = \mathbf{Q}^\top$，这使得求解正交矩阵的逆矩阵变得极其简单，只需进行转置操作。第三，正交矩阵的行列式的绝对值为1，即$|\det(\mathbf{Q})| = 1$。

在大语言模型的架构设计中，正交性有着多方面的应用。首先，正交初始化是一种常用的权重初始化方法。与随机高斯初始化或Xavier初始化不同，正交初始化将权重矩阵初始化为正交矩阵，这在理论上可以防止初始化时的梯度消失或爆炸问题，因为正交矩阵的奇异值全部为1。

其次，Gram-Schmidt正交化过程是构建正交基的标准算法，在特征提取和表示学习中经常被使用。例如，在对比学习中，通过Gram-Schmidt正交化可以移除表示中的冗余成分，使得不同特征方向捕捉不同的信息。

第三，正交约束在优化中被用于防止权重矩阵的秩退化。在某些正则化方法中，我们在优化目标中加入正交性惩罚项，鼓励权重矩阵的列向量相互正交。这种约束有助于提高模型的稳定性和泛化能力。

第四，傅里叶变换和正交基扩展是信号处理和自然语言处理中的重要工具。虽然自然语言处理很少直接使用傅里叶变换，但在处理序列数据的某些场景下，正交变换仍然是有价值的分析工具。

### 1.1.8 矩阵范数与度量

矩阵范数是衡量矩阵"大小"的标准，在深度学习中有着广泛的应用。矩阵范数将矩阵映射到非负实数，满足非负性、齐次性和三角不等式等性质。常用的矩阵范数包括Frobenius范数、谱范数、核范数和1-范数/∞-范数。

Frobenius范数是最直观的矩阵范数，定义为所有元素平方和的平方根：$\|\mathbf{A}\|_F = \sqrt{\sum_{i,j} a_{ij}^2}$​​。它可以看作是矩阵展开为向量后的L2范数，具有旋转不变性。在深度学习中，Frobenius范数常用于权重衰减（Weight Decay）正则化，通过惩罚大权重来防止过拟合。

谱范数（Spectral Norm）是矩阵的最大奇异值：$\|\mathbf{A}\|_2 = \sigma_{\max}(\mathbf{A})$。它对应于从$\mathbb{R}^n$到$\mathbb{R}^m$的线性变换中最大的拉伸因子。在神经网络的稳定性分析和Lipschitz约束中，谱范数是核心概念。谱归一化（Spectral Normalization）是一种重要的权重归一化技术，它通过将权重矩阵除以其谱范数来约束网络函数的Lipschitz常数。

核范数（Nuclear Norm）是矩阵所有奇异值的和：$\|\mathbf{A}\|_* = \sum_i \sigma_i(\mathbf{A})$。核范数是Frobenius范数和谱范数之间的折中，常用于矩阵补全（Matrix Completion）和低秩矩阵恢复问题。在推荐系统和缺失数据插补中，核范数正则化可以鼓励解的低秩性质。

1-范数和∞-范数分别是列范数和行范数：$\|\mathbf{A}\|_1 = \max_j \sum_i |a_{ij}|$和$\|\mathbf{A}\|_\infty = \max_i \sum_j |a_{ij}|$。这些范数在稀疏优化和线性规划中有重要应用，但在深度学习中使用较少。

矩阵范数的选择取决于具体问题的需求。在模型压缩和低秩近似中，我们关心如何用少量的奇异值最好地近似原始矩阵，这涉及到部分和（Partial Sum）范数$\sum_{i=1}^k \sigma_i$​。在分析梯度流和稳定性时，谱范数最重要，因为它决定了信息放大或衰减的上界。在正则化中，Frobenius范数因其可导性好而最常用。

### 1.1.9 矩阵分解的深化理解

除了前面介绍的奇异值分解，矩阵分解还包括LU分解、QR分解、特征值分解和Cholesky分解等多种方法。每种分解都有其特定的应用场景和数值性质。

LU分解将矩阵分解为下三角矩阵$\mathbf{L}$和上三角矩阵$\mathbf{U}$的乘积：$\mathbf{A} = \mathbf{L}\mathbf{U}$。对于方阵，如果主元都不为零，则LU分解存在；如果进行行交换（带置换矩阵$\mathbf{P}$），则PLU分解总是存在。LU分解的主要用途是高效求解线性方程组$\mathbf{A}\mathbf{x} = \mathbf{b}$，因为前向和后向替换的复杂度是$O(n^2)$而不是高斯消元的$O(n^3)$。

QR分解将矩阵分解为正交矩阵$\mathbf{Q}$和上三角矩阵$\mathbf{R}$的乘积：$\mathbf{A} = \mathbf{Q}\mathbf{R}$。QR分解有多种计算方法，包括Gram-Schmidt正交化、Householder变换和Givens旋转。QR分解在线性最小二乘问题中有重要应用，因为正规方程$\mathbf{A}^\top \mathbf{A}\mathbf{x} = \mathbf{A}^\top \mathbf{b}$的解等价于求解$\mathbf{R}\mathbf{x} = \mathbf{Q}^\top \mathbf{b}$。

特征值分解将方阵分解为特征向量矩阵和特征值对角矩阵的乘积：$\mathbf{A} = \mathbf{V}\mathbf{\Lambda}\mathbf{V}^{-1}$。只有可对角化矩阵（具有完整特征向量基）才能进行这种分解。对于对称矩阵，特征值分解总是可行的，且特征向量矩阵是正交的。特征值分解在动力系统分析、主成分分析和谱聚类中都有应用。

Cholesky分解是LU分解的特例，只适用于对称正定矩阵。它将矩阵分解为下三角矩阵与其转置的乘积：$\mathbf{A} = \mathbf{L}\mathbf{L}^\top$。Cholesky分解的数值稳定性好，计算量约为LU分解的一半，在高斯过程回归和二次优化中有广泛应用。

### 1.1.10 Kronecker积与向量化

Kronecker积是两个矩阵之间的特殊二元运算，它将一个$m \times n$的矩阵与一个$p \times q$的矩阵组合成一个$mp \times nq$的大矩阵。对于矩阵$\mathbf{A} \in \mathbb{R}^{m \times n}$和$\mathbf{B} \in \mathbb{R}^{p \times q}$，它们的Kronecker积定义为：
$$
\mathbf{A} \otimes \mathbf{B} = \begin{bmatrix} a_{11}\mathbf{B} & a_{12}\mathbf{B} & \cdots & a_{1n}\mathbf{B} \\ a_{21}\mathbf{B} & a_{22}\mathbf{B} & \cdots & a_{2n}\mathbf{B} \\ \vdots & \vdots & \ddots & \vdots \\ a_{m1}\mathbf{B} & a_{m2}\mathbf{B} & \cdots & a_{mn}\mathbf{B} \end{bmatrix}
$$
Kronecker积具有许多有用的代数性质，包括结合律$(\mathbf{A} \otimes \mathbf{B}) \otimes \mathbf{C} = \mathbf{A} \otimes (\mathbf{B} \otimes \mathbf{C})$、混合积性质 $(\mathbf{A} \otimes \mathbf{B})(\mathbf{C} \otimes \mathbf{D}) = (\mathbf{A}\mathbf{C}) \otimes (\mathbf{B}\mathbf{D})$（当维度匹配时）、转置性质$(\mathbf{A} \otimes \mathbf{B})^\top = \mathbf{A}^\top \otimes \mathbf{B}^\top$。

在深度学习中，Kronecker积的主要应用包括权重共享、参数高效微调和特定网络结构的设计。例如，MobileNet中的深度可分离卷积可以用Kronecker积来表示，这有助于理解其参数效率。在模型并行化中，Kronecker积可以帮助我们将大矩阵运算分解为多个小矩阵运算的组合，从而在多个计算设备上分布式执行。

向量化（Vectorization）是将矩阵转换为列向量的操作，记为$\text{vec}(\mathbf{A})$或$\mathbf{A}^\vee$。如果$\mathbf{A}$ 是$m \times n$的矩阵，则$\text{vec}(\mathbf{A})$是一个$mn \times 1$的列向量，按列优先的顺序排列矩阵元素。向量化操作与Kronecker积结合可以简化矩阵方程的表示。

具体来说，对于矩阵方程$\mathbf{X}\mathbf{A}\mathbf{B} = \mathbf{C}$，通过向量化操作可以将其转化为线性方程$\text{vec}(\mathbf{XAB}) = (\mathbf{B}^\top \otimes \mathbf{A})\text{vec}(\mathbf{X}) = \text{vec}(\mathbf{C})$。这种转化在推导反向传播公式和优化算法时非常有用，因为它将复杂的矩阵运算转化为标准的矩阵-向量乘积。

### 1.1.11 张量网络与高维运算

张量网络是用低维张量通过网络结构表示高维张量的方法，在物理学和机器学习中都有重要应用。一个张量网络由若干个节点（每个节点是一个张量）和连接节点的边（每个边代表张量的一个维度）组成。张量网络的核心思想是用多个小张量的乘积之和来表示一个巨大的高维张量，从而实现高效的存储和计算。

在大语言模型中，张量网络的思维方式有助于理解复杂的计算结构。Transformer中的注意力机制可以被看作一个三阶张量（查询、键、值的交互）被分解为多个低阶张量的组合。具体的，注意力权重矩阵$\mathbf{A} = \text{softmax}\left(\frac{\mathbf{Q}\mathbf{K}^\top}{\sqrt{d_k}}\right)$可以看作是查询张量和键张量的收缩。

张量网络在模型压缩和高效推理中有着重要的应用价值。通过将大型权重张量分解为张量网络的形式，可以显著减少参数量和计算量。例如，CP分解可以将一个$n \times n \times n$的三阶张量表示为$r$个秩一张量的和，参数复杂度从$O(n^3)$降低到$O(r \cdot 3n)$。

从张量网络的角度来看，矩阵乘法是连接两个张量的最基本操作。两个二阶张量（矩阵）的乘法可以看作是收缩掉两个张量的一个公共维度。更复杂的网络结构如树状张量网络（Tree Tensor Network）和分层张量分解（Hierarchical Tucker Decomposition）可以用于表示高阶交互关系。

张量运算的高效实现是现代深度学习框架的核心能力之一。现代GPU架构专门优化了张量运算，包括矩阵乘法、卷积运算和批处理操作。理解张量运算的数学本质有助于编写高效的代码和诊断性能瓶颈。例如，在PyTorch中，通过仔细规划张量的内存布局和运算顺序，可以显著减少不必要的内存分配和数据拷贝。

### 1.1.12 批处理与并行计算的张量视图

批处理（Batch Processing）是深度学习训练和推理的基本范式，它允许同时处理多个样本以提高计算效率。从张量的角度来看，批处理是在现有维度之外增加一个新的批处理维度。设单个样本的特征表示是形状为$(S,D)$的二维张量（序列长度 × 嵌入维度），则一个批次的表示就是形状为 $(B,S,D)$ 的三维张量，其中$B$是批大小。

批处理的数学优势来自于矩阵运算的并行性。当我们计算批次中所有样本的前向传播时，如果使用张量运算而非循环，可以一次性完成所有样本的计算。现代GPU的并行架构非常适合这种批处理计算，因为它可以将不同样本的计算分配到不同的处理单元上同时执行。数学上，批处理相当于将多个独立的矩阵运算堆叠成一个大的张量运算。

注意力机制的批处理实现是理解这一概念的良好例子。单个样本的注意力计算涉及形状为$(S,D)$的查询、键和值张量，其中$S$是序列长度。对于一个批次，我们得到形状为$(B, S, D)$的张量。注意力分数的计算$\mathbf{Q}\mathbf{K}^\top$在批处理情况下变成$(B, S, S)$的三维张量运算。在实际实现中，这个运算被高度优化，GPU可以同时计算批次中所有样本的注意力分数。

微批处理（Micro-batch）是批处理的一个变体，用于处理超大序列或有限GPU内存的情况。当单个样本太大以至于无法在GPU内存中容纳时，可以将批次进一步划分为更小的微批次，每个微批次独立计算。这种技术在训练大语言模型时尤为重要，因为长序列可能消耗大量内存。

梯度累积是另一种与批处理相关的技术。当批大小受限于GPU内存时，我们可以通过梯度累积来模拟更大的有效批大小。具体来说，我们先计算若干个小批次的梯度，将它们累加起来，然后使用累加的梯度进行一次参数更新。这样，既保证了一次更新使用的样本数量（有效批大小），又不受单批次大小的限制。梯度累积在数学上等价于使用更大的批次进行训练，因为梯度是线性的。

### 1.1.13 计算复杂度与内存效率

在大语言模型中，矩阵和张量运算的计算复杂度和内存效率是核心关注点。理解不同运算的资源需求对于优化模型设计和硬件利用至关重要。

矩阵乘法的计算复杂度是$O(mnp)$，其中$\mathbf{A} \in \mathbb{R}^{m \times n}$，$\mathbf{B} \in \mathbb{R}^{n \times p}$，输出$\mathbf{C} \in \mathbb{R}^{m \times p}$。这意味着计算一个$d \times d$权重矩阵与$d \times 1$向量的乘积需要$O(d^2)$次标量乘法和加法。对于大语言模型中的全连接层，隐藏维度$d$通常在数千量级，因此单个层的计算量是相当可观的。

注意力机制的计算复杂度与序列长度的平方成正比。具体来说，对于序列长度$S$和注意力维度 $d$，注意力分数的计算$\mathbf{Q}\mathbf{K}^\top$需要$O(S^2 d)$的计算量，注意力权重与值向量的乘积同样需要$O(S^2 d)$。这就是为什么Transformer在处理长序列时面临计算挑战，也是为什么许多研究致力于开发高效的注意力变体，如线性注意力、稀疏注意力和分层注意力。

内存效率不仅与参数数量有关，还与激活值的存储需求有关。在前向传播过程中，每一层的输入和输出都需要被保存用于反向传播。对于深层网络和长序列，激活值的内存消耗可能超过参数本身。梯度检查点（Gradient Checkpointing）是一种常用的内存优化技术，它通过在前向传播时只保存部分层的激活值，在反向传播时重新计算被省略的激活值来节省内存，代价是增加额外的计算量。

混合精度训练是另一种重要的效率优化技术。它使用半精度浮点数（FP16）或更低精度（如BF16、INT8）进行大部分计算，只在关键步骤使用全精度（FP32）以保持数值稳定性。混合精度训练可以将内存消耗减半，并将计算速度提高近一倍。数学上，混合精度利用了现代GPU对低精度运算的专门优化，这些运算的吞吐量通常是全精度运算的数倍。

模型并行化将大模型分布在多个计算设备上，是训练超大规模语言模型的必要技术。张量并行（Tensor Parallelism）在模型的宽度维度上划分参数，流水线并行（Pipeline Parallelism）在深度维度上划分层，而数据并行（Data Parallelism）则复制整个模型在多个数据批次上并行训练。理解这些并行策略的数学基础——如何将矩阵运算分解为可以在不同设备上独立执行的子运算——对于设计和实现高效的大规模训练系统至关重要。