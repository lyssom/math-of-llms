## 1.2 概率论与统计
### 1.2.1 随机变量与概率分布

概率论是研究随机现象规律性的数学分支，为大语言模型提供了处理不确定性的理论基础。在自然语言处理中，文本生成本质上是一个随机过程：给定前文的条件下，下一个词的选择遵循某种概率分布。语言模型的训练目标就是学习这个条件概率分布，使得生成的文本既流畅又符合语义逻辑。理解随机变量和概率分布的概念，是掌握语言模型概率本质的必要前提。

随机变量是样本空间到实数集的映射，它将随机试验的结果数值化。根据取值方式的不同，随机变量分为离散随机变量和连续随机变量。离散随机变量只能取有限或可数无穷个值，如抛硬币的结果（正面或反面）、掷骰子的点数（1到6）、词汇表中的词索引等。连续随机变量可以取任意实数值或实数区间内的值，如词语的嵌入向量、注意力权重、神经网络的激活值等。在大语言模型中，我们同时处理这两类随机变量：词索引是离散的，而连续空间中的嵌入表示和隐藏状态则是连续的。

概率质量函数（Probability Mass Function，PMF）是描述离散随机变量概率分布的函数。对于离散随机变量$X$，其PMF记为$P(X = x) = p(x)$，表示$X$取特定值$x$的概率。PMF必须满足两个基本性质：非负性$p(x) \geq 0$对所有$x$成立，以及归一性$\sum_{x} p(x) = 1$。在大语言模型中，词汇表上的概率分布就是典型的PMF。对于词汇表大小为$V$的语言模型，输出层的预测分布是一个$V$维的概率向量，其元素表示生成词汇表中每个词的概率。

伯努利分布（Bernoulli Distribution）是最简单的离散分布，描述单次二元试验的成功概率。设随机变量$X \sim \text{Bernoulli}(p)$，则$P(X = 1) = p$，$P(X = 0) = 1-p$，其中$p \in [0, 1]$是成功概率。伯努利分布的期望为$E[X] = p$，方差为$\text{Var}(X) = p(1-p)$。在语言模型中，伯努利分布可用于描述二元随机事件，如判断一个词是否属于某个类别、一个词是否被mask掉、或经过Dropout操作后某个神经元是否被激活等。

二项分布（Binomial Distribution）是n次独立伯努利试验中成功次数的分布。设$X \sim \text{Binomial}(n, p)$，则$P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}$，其中$k = 0, 1, \ldots, n$。二项分布的期望为$E[X] = np$，方差为$\text{Var}(X) = np(1-p)$。二项分布在语言模型中的应用包括描述一批样本中被mask的词的数量、计算分类任务中的正确预测数量等。

类别分布（Categorical Distribution）是伯努利分布向多值情况的推广，也称为多项分布（Multinomial Distribution）的一次试验版本。设随机变量$X$在$K$个类别上服从类别分布$X \sim \text{Categorical}(p_1, p_2, \ldots, p_K)$，则$P(X = k) = p_k$，其中$p_k \geq 0$且$\sum_{k=1}^{K} p_k = 1$。语言模型的输出层正是类别分布的一个典型应用：模型为词汇表中的每个词分配一个概率，表示生成该词的可能性。Softmax函数将模型的原始输出（logits）转换为有效的类别概率分布。

连续随机变量由概率密度函数（Probability Density Function，PDF）描述。与PMF不同，PDF在单点的取值不代表概率，概率由PDF在区间上的积分给出。设连续随机变量$X$的PDF为$f(x)$，则$X$ 落在区间$[a,b]$的概率为$P(a \leq X \leq b) = \int_a^b f(x) dx$。PDF同样满足非负性$f(x) \geq 0$和归一性$\int_{-\infty}^{\infty} f(x) dx = 1$。

均匀分布（Uniform Distribution）是最简单的连续分布。设$X \sim \text{Uniform}(a, b)$，则其PDF为$f(x) = \frac{1}{b-a}$当$a \leq x \leq b$，否则为0。均匀分布的期望为$E[X] = \frac{a+b}{2}$，方差为$\text{Var}(X) = \frac{(b-a)^2}{12}$​。在语言模型中，均匀分布可用于权重初始化、随机采样策略的设计，以及某些正则化技术的理论基础。

指数分布（Exponential Distribution）描述独立事件发生的时间间隔。设$X \sim \text{Exponential}(\lambda)$，则其PDF为$f(x) = \lambda e^{-\lambda x}$当$x \geq 0$，其中$\lambda > 0$是率参数。指数分布的期望为$E[X] = \frac{1}{\lambda}$​，方差为$\text{Var}(X) = \frac{1}{\lambda^2}$​。指数分布在语言模型中的应用包括描述某些随机过程的到达时间间隔，以及在概率图模型中作为共轭先验使用。
![[dist_relation.drawio.png]]

### 1.2.2 期望、方差与协方差

期望、方差和协方差是概率论中最重要的一阶和二阶统计量，它们刻画了随机变量的集中趋势、离散程度和相互关系。这些统计量在机器学习的理论和实践中都有广泛应用，从损失函数的定义到模型性能的评价，从梯度计算的期望到模型不确定性的估计，都离不开这些基本概念。

期望（Expectation）是随机变量取值的加权平均，描述了随机变量的"中心"位置。对于离散随机变量$X$，其期望定义为$E[X] = \sum_x x \cdot p(x)$。对于连续随机变量$X$，期望定义为$E[X] = \int_{-\infty}^{\infty} x \cdot f(x) dx$。期望具有线性性质：对任意常数$a, b$和随机变量$X, Y$，有$E[aX + bY] = aE[X] + bE[Y]$。这一性质在反向传播算法的推导中至关重要，因为我们可以将期望操作与梯度操作交换次序。

条件期望是在给定某些信息的条件下对随机变量的期望。条件期望$E[Y | X = x]$是$x$的函数，记为 $g(x)$。条件期望的一个重要性质是全期望公式：$E[Y] = E[E[Y | X]]$。在语言模型中，条件期望用于描述在给定上下文的条件下，下一个词的条件概率分布的期望特性。例如，困惑度（Perplexity）的计算就隐含了条件期望的概念。

方差（Variance）衡量随机变量取值的离散程度，定义为$\text{Var}(X) = E[(X - E[X])^2]$。根据期望的线性性质，方差可以展开为$\text{Var}(X) = E[X^2] - (E[X])^2$，这个公式在计算方差时更加实用。方差的平方根称为标准差（Standard Deviation），记为$\sigma(X) = \sqrt{\text{Var}(X)}$​，它与随机变量$X$具有相同的量纲，便于解释和比较。

方差的性质包括：非负性$\text{Var}(X) \geq 0$；对常数$c$有$\text{Var}(cX) = c^2 \text{Var}(X)$；若$X$和$Y$独立，则$\text{Var}(X + Y) = \text{Var}(X) + \text{Var}(Y)$。需要注意的是，一般情况下$\text{Var}(X + Y) \neq \text{Var}(X) + \text{Var}(Y)$，只有当$X$和$Y$不相关时等号才成立。在深度学习中，方差用于分析梯度的波动、权重初始化的尺度选择，以及模型输出的不确定性估计。

协方差（Covariance）衡量两个随机变量之间的线性相关程度。对于两个随机变量$X$和$Y$，协方差定义为$\text{Cov}(X, Y) = E[(X - E[X])(Y - E[Y])]$。协方差可以展开为$\text{Cov}(X, Y) = E[XY] - E[X]E[Y]$。当$\text{Cov}(X, Y) > 0$时，$X$和$Y$倾向于同向变化；当$\text{Cov}(X, Y) < 0$时，$X$和$Y$倾向于反向变化；当$\text{Cov}(X, Y) = 0$时，$X$和$Y$线性无关。

协方差矩阵是多维随机变量的二阶中心矩描述。对于$n$维随机向量$\mathbf{X} = (X_1, X_2, \ldots, X_n)^\top$，其协方差矩阵$\mathbf{\Sigma}$是一个$n \times n$的对称半正定矩阵，其中第$(i, j)$个元素为$\Sigma_{ij} = \text{Cov}(X_i, X_j)$。协方差矩阵的对角线元素是各随机变量的方差，非对角线元素是变量之间的协方差。协方差矩阵在大语言模型中的应用包括：描述词嵌入向量的分布特性、分析不同层之间隐藏状态的相关性，以及在变分自编码器中定义潜在空间的先验分布。

相关系数（Correlation Coefficient）是标准化的协方差，定义为$\rho_{XY} = \frac{\text{Cov}(X, Y)}{\sigma(X)\sigma(Y)}$​。相关系数的取值范围为$[−1,1]$，其中$1$表示完全正相关，$−1$表示完全负相关，$0$表示线性无关。相关系数消除了量纲的影响，使得不同变量对之间的相关性可以直接比较。在语言模型研究中，相关系数可用于分析不同词嵌入维度之间的冗余程度，以及评估模型对不同类型输入的响应一致性。

矩（Moment）是随机变量幂次期望的统称。$k$阶原点矩定义为$m_k = E[X^k]$，$k$阶中心矩定义为$\mu_k = E[(X - E[X])^k]$。一阶原点矩是期望，二阶中心矩是方差。偏度（Skewness）由三阶中心矩归一化得到，描述分布的对称性；峰度（Kurtosis）由四阶中心矩归一化得到，描述分布的尾部厚度。这些高阶矩在统计分析中有一定应用，但在深度学习中的直接应用较少。

矩母函数（Moment Generating Function，MGF）是$M(t) = E[e^{tX}]$，它唯一确定了随机变量的概率分布（在其存在的范围内）。通过对矩母函数求导并在$t=0$处求值，可以得到各阶矩：$m_k = M^{(k)}(0)$。特征函数是矩母函数的复数形式$\phi(t) = E[e^{itX}]$，它总是存在的，且同样唯一确定概率分布。在某些深度学习应用中，如分析神经网络输出的分布特性，特征函数提供了有用的分析工具。

### 1.2.3 高斯分布与多元高斯

高斯分布（Gaussian Distribution），也称为正态分布（Normal Distribution），是概率论中最重要的连续分布，在统计学和机器学习中有着核心地位。高斯分布之所以如此重要，源于多个方面的原因：从理论上看，中心极限定理表明大量独立随机变量之和趋向于高斯分布；从应用上看，许多自然现象和测量误差都近似服从高斯分布；从数学上看，高斯分布在卷积、傅里叶变换和微分方程等运算下保持封闭形式，这使得高斯分布成为最易于处理的分布之一。

一维高斯分布的概率密度函数为$f(x) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)$，记为$X \sim \mathcal{N}(\mu, \sigma^2)$。其中$\mu$是均值参数，$\sigma^2$是方差参数，$\sigma$是标准差。标准高斯分布（或称单位高斯分布）是均值为0、方差为1的特殊高斯分布，记为$\mathcal{N}(0, 1)$，其PDF为$\phi(x) = \frac{1}{\sqrt{2\pi}} e^{-x^2/2}$。任何高斯随机变量都可以通过标准化变换$Z = \frac{X-\mu}{\sigma}$转换为标准高斯随机变量。

高斯分布的期望为$\mu$，方差为$\sigma^2$，这从参数命名就可以看出。高斯分布的众数（概率密度最大的点）和中位数都等于均值。高斯分布的偏度为0（完全对称），峰度为3（相对于标准正态分布）。高斯分布的熵（稍后详述）为$H(X) = \frac{1}{2}\log(2\pi e\sigma^2)$，这表明在给定方差的所有连续分布中，高斯分布具有最大的熵，即最大的不确定性。
![[gauss_dist.drawio.png]]
多元高斯分布是一维高斯分布向多维空间的推广。设$\mathbf{X} = (X_1, X_2, \ldots, X_d)^\top$是一个$d$维随机向量，若$\mathbf{X}$服从多元高斯分布，则记为$\mathbf{X} \sim \mathcal{N}(\boldsymbol{\mu}, \mathbf{\Sigma})$，其中$\boldsymbol{\mu} \in \mathbb{R}^d$是均值向量，$\mathbf{\Sigma} \in \mathbb{R}^{d \times d}$是协方差矩阵（必须是对称半正定的）。多元高斯分布的PDF为：
$$
f(\mathbf{x}) = \frac{1}{(2\pi)^{d/2} |\mathbf{\Sigma}|^{1/2}} \exp\left(-\frac{1}{2}(\mathbf{x} - \boldsymbol{\mu})^\top \mathbf{\Sigma}^{-1}(\mathbf{x} - \boldsymbol{\mu})\right)\tag{1.2.1}
$$
其中$|\mathbf{\Sigma}|$ 是协方差矩阵的行列式，$\mathbf{\Sigma}^{-1}$是协方差矩阵的逆矩阵（称为精度矩阵）。二次型 $(\mathbf{x} - \boldsymbol{\mu})^\top \mathbf{\Sigma}^{-1}(\mathbf{x} - \boldsymbol{\mu})$称为马氏距离（Mahalanobis Distance），它考虑了各变量之间的相关性。

多元高斯分布具有许多重要的性质。首先，边缘分布仍然是高斯分布：若$\mathbf{X} \sim \mathcal{N}(\boldsymbol{\mu}, \mathbf{\Sigma})$，则任意分量$X_i$服从一维高斯分布$\mathcal{N}(\mu_i, \Sigma_{ii})$。其次，线性变换保持高斯性：若$\mathbf{X} \sim \mathcal{N}(\boldsymbol{\mu}, \mathbf{\Sigma})$，则对任意矩阵 $\mathbf{A}$和向量$\mathbf{b}$，有$\mathbf{Y} = \mathbf{A}\mathbf{X} + \mathbf{b} \sim \mathcal{N}(\mathbf{A}\boldsymbol{\mu} + \mathbf{b}, \mathbf{A}\mathbf{\Sigma}\mathbf{A}^\top)$。这一性质在变分推断和高斯过程回归中非常重要。

条件分布是多元高斯分布最优美也最实用的性质之一。考虑将$\mathbf{X}$划分为两个子向量$\mathbf{X}_a$和$\mathbf{X}_b$​，均值和协方差相应地分块为：
$$
\boldsymbol{\mu} = \begin{bmatrix} \boldsymbol{\mu}_a \\ \boldsymbol{\mu}_b \end{bmatrix}, \quad \mathbf{\Sigma} = \begin{bmatrix} \mathbf{\Sigma}_{aa} & \mathbf{\Sigma}_{ab} \\ \mathbf{\Sigma}_{ba} & \mathbf{\Sigma}_{bb} \end{bmatrix}\tag{1.2.2}
$$
则给定$\mathbf{X}_b$时$\mathbf{X}_a$的条件分布仍然是高斯分布：
$$
\mathbf{X}_a | \mathbf{X}_b = \mathbf{x}_b \sim \mathcal{N}(\boldsymbol{\mu}_{a|b}, \mathbf{\Sigma}_{a|b})\tag{1.2.3}
$$
其中条件均值为$\boldsymbol{\mu}_{a|b} = \boldsymbol{\mu}_a + \mathbf{\Sigma}_{ab}\mathbf{\Sigma}_{bb}^{-1}(\mathbf{x}_b - \boldsymbol{\mu}_b)$，条件协方差为$\mathbf{\Sigma}_{a|b} = \mathbf{\Sigma}_{aa} - \mathbf{\Sigma}_{ab}\mathbf{\Sigma}_{bb}^{-1}\mathbf{\Sigma}_{ba}$​。注意条件协方差不依赖于观测值$\mathbf{x}_b$，这是一个重要的性质。条件分布在高斯过程回归、卡尔曼滤波和贝叶斯线性回归中有着核心应用。

在大语言模型中，高斯分布扮演着多种重要角色。在权重初始化方面，Xavier初始化和He初始化都假设权重服从某种高斯分布（或均匀分布），以确保信号在各层之间平稳传播。具体而言，He初始化使用均值为0、方差为$\frac{2}{n_{\text{in}}}$的高斯分布，其中$n_{\text{in}}$是输入神经元的数量。

在正则化技术方面，Dropout可以被解释为对神经网络进行高斯近似。具体来说，当Dropout率为 $p$时，等效的高斯Dropout在权重上引入方差为$\frac{p}{1-p}$的高斯噪声。变分Dropout（Variational Dropout）进一步将Dropout解释为贝叶斯推断，噪声的参数通过变分推断学习得到。

在输出建模方面，高斯输出分布用于回归任务，但在语言模型中更常用的是分类分布。某些语言模型变体使用高斯混合模型来表示输出分布，以捕获更复杂的多模态特性。在对话系统中，高斯分布可用于建模响应的不确定性，使得模型能够生成多样化的回复。

在高斯过程和贝叶斯优化中，高斯过程是函数的先验分布，用于建模连续的随机过程。高斯过程回归在超参数优化、神经架构搜索和语言模型微调中有着应用。高斯过程的一个优势是它提供了预测的不确定性估计，这对于主动学习和探索-利用权衡很有价值。

在变分自编码器和生成模型中，高斯分布通常作为潜在空间的先验分布。标准VAE假设潜在变量服从标准高斯分布$\mathcal{N}(0, \mathbf{I})$，通过编码器学习将输入映射到该分布的参数（均值和对数方差），再通过重参数化技巧进行采样，最后通过解码器重建原始输入。大语言模型的某些扩展（如结合VAE的表示学习）也采用了类似的思想。

### 1.2.4 KL散度与交叉熵

KL散度（Kullback-Leibler Divergence）和交叉熵（Cross Entropy）是信息论中的核心概念，在机器学习特别是大语言模型中有着广泛应用。它们用于衡量两个概率分布之间的差异，是定义损失函数和分析模型行为的重要工具。

信息论的基本概念始于熵（Entropy）的定义。对于离散随机变量$X$及其概率分布$p(x)$，熵定义为$H(X) = H(p) = -\sum_x p(x) \log p(x)$。熵衡量了随机变量不确定性的大小，单位为比特（bit，当使用以2为底的对数时）或奈特（nat，当使用自然对数时）。直观上，熵越大，分布越"平坦"（不确定性高）；熵越小，分布越"尖锐"（确定性高）。对于确定性分布（某个$x$的概率为1，其他为0），熵为0。

联合熵（Joint Entropy）是两个随机变量的联合分布的熵：$H(X, Y) = -\sum_x \sum_y p(x, y) \log p(x, y)$。条件熵（Conditional Entropy）是给定一个随机变量时另一个随机变量的熵：$H(X | Y) = -\sum_x \sum_y p(x, y) \log p(x | y) = H(X, Y) - H(Y)$。链式法则给出了多个随机变量的联合熵分解：$H(X_1, X_2, \ldots, X_n) = \sum_{i=1}^n H(X_i | X_1, \ldots, X_{i-1})$。

互信息（Mutual Information）衡量两个随机变量之间的信息共享程度：$I(X; Y) = H(X) + H(Y) - H(X, Y) = H(X) - H(X | Y) = H(Y) - H(Y | X)$。互信息始终非负，当且仅当$X$和$Y$独立时互信息为0。在语言模型中，互信息可用于分析不同位置或不同层之间的信息流动，以及评估词嵌入中捕获的语义信息量。

KL散度衡量两个概率分布之间的"距离"（严格来说不是真正的距离，因为它不满足对称性和三角不等式）。对于两个离散概率分布$p$和$q$，KL散度定义为：
$$ 
D_{\text{KL}}(p \| q) = \sum_x p(x) \log \frac{p(x)}{q(x)}\tag{1.2.4}
$$
KL散度可以理解为使用分布$q$来编码来自分布$p$的样本时所需要的额外信息量。从公式可以看出，KL散度是非负的（由Jensen不等式保证），即$D_{\text{KL}}(p \| q) \geq 0$，且当且仅当$p=q$时KL散度为0。然而，KL散度不对称，即一般情况下$D_{\text{KL}}(p \| q) \neq D_{\text{KL}}(q \| p)$。

对于连续随机变量（分布用PDF表示），KL散度的定义为：
$$
D_{\text{KL}}(p \| q) = \int_{-\infty}^{\infty} p(x) \log \frac{p(x)}{q(x)} dx\tag{1.2.5}
$$
在大语言模型中，KL散度有多种重要应用。在变分推断中，我们希望用简单的近似分布$q$来逼近复杂的后验分布$p$，优化目标就是最小化$D_{\text{KL}}(q \| p)$或$D_{\text{KL}}(p \| q)$，具体选择取决于变分推断的目标。在VAE中，损失函数包含重构项和KL正则项，后者就是编码器分布与标准高斯先验之间的KL散度。

在强化学习与语言模型的结合中，KL散度用于限制策略更新的幅度，确保新策略不会偏离旧策略太远。这在近端策略优化（PPO）等算法中非常重要。在知识蒸馏中，KL散度用于衡量学生模型和教师模型输出分布之间的差异，使学生模型能够学习教师模型的知识。

交叉熵与KL散度密切相关。对于两个分布$p$和$q$，交叉熵定义为$H(p, q) = -\sum_x p(x) \log q(x)$。交叉熵可以分解为熵与KL散度之和：$H(p, q) = H(p) + D_{\text{KL}}(p \| q)$。当$p$是真实分布而$q$是模型预测分布时，$H(p)$是常数（因为真实分布固定），因此最小化交叉熵等价于最小化KL散度$D_{\text{KL}}(p \| q)$。
![[msg_relation.drawio.png]]

在大语言模型的训练中，交叉熵损失是最常用的损失函数。具体而言，对于每个位置$t$，语言模型预测下一个词的概率分布为$q(y_t | y_{<t})$，而真实分布是"正确答案"的one-hot编码$p(y_t)$。该位置的交叉熵损失为$-\log q(y_t^* | y_{<t})$，其中$y_t^*$​ 是真实词元。整个序列或批次的损失是这些位置损失的均值或和。交叉熵损失的优势在于它直接与对数似然相关，最小化交叉熵等价于最大化数据的对数似然。

从优化的角度看，交叉熵损失相对于模型输出（logits）的梯度具有简洁的形式。设$z_i$是第$i$个类别的logit，softmax输出为$q_i = \frac{\exp(z_i)}{\sum_j \exp(z_j)}$​，真实标签为$p_i$（在多类分类中为one-hot编码），则交叉熵损失相对于$z_i$的梯度为$p_i - q_i$​。这个简洁的梯度形式是交叉熵损失被广泛采用的重要原因之一。

标签平滑（Label Smoothing）是一种常用的正则化技术，它将硬标签（one-hot编码）替换为软标签，即在真实类别上赋予$1 - \epsilon$的概率，在其他类别上均匀分配$\epsilon$的概率。标签平滑可以防止模型对训练数据过度自信，提高泛化能力。从KL散度的角度看，标签平滑相当于在训练时使用真实分布与均匀分布的混合作为目标分布。

KL散度在不同场景下的不同形式反映了其灵活性。正向$D_{\text{KL}}(p \| q)$鼓励$q$覆盖$p$的所有模式（即$q$的支持集必须包含$p$的支持集），而反向$D_{\text{KL}}(q \| p)$则鼓励$q$找到一个主要的模式并紧密地拟合它。在变分推断中，选择哪种KL形式取决于我们希望对近似分布施加什么样的约束。在生成模型中，这种选择影响着生成样本的多样性和质量。

### 1.2.5 统计推断与参数估计

统计推断是利用样本数据对总体特征进行推断的过程，包括参数估计和假设检验两大类方法。在大语言模型中，统计推断的思想贯穿于模型训练、参数优化和性能评估的全过程。理解最大似然估计、贝叶斯估计和期望传播等统计推断方法，对于深入理解语言模型的工作原理和改进模型设计都有重要意义。

最大似然估计（Maximum Likelihood Estimation，MLE）是最基本也是最重要的参数估计方法。设我们有观测数据$\mathcal{D} = \{x_1, x_2, \ldots, x_n\}$，假设这些数据独立同分布（i.i.d.）于某个概率分布$p(x | \theta)$，其中$\theta$是未知参数。似然函数定义为$L(\theta) = \prod_{i=1}^n p(x_i | \theta)$，对数似然函数为$\ell(\theta) = \log L(\theta) = \sum_{i=1}^n \log p(x_i | \theta)$。最大似然估计就是找到使对数似然最大的参数值：$\hat{\theta}_{\text{MLE}} = \arg\max_\theta \ell(\theta)$。

在大语言模型中，MLE是训练的标准方法。语言模型的训练目标是最大化训练语料库的对数似然，即给定前文的条件下预测下一个词的对数概率之和。由于训练数据通常被组织为序列，对数似然可以分解为序列中每个位置的条件对数概率之和。训练过程就是使用随机梯度下降等优化算法来最大化这个目标函数。

最大似然估计具有一些重要的渐近性质。在正则条件下，当样本量$n \to \infty$时，MLE是相合的（收敛于真实参数值）、渐近正态的（服从以真实参数为均值、费希尔信息矩阵逆为方差的正态分布）和渐近有效的（方差达到克拉美-罗下界）。这些性质为MLE在大样本场景下的应用提供了理论保障。

贝叶斯估计是另一种参数估计方法，它将参数视为随机变量并使用贝叶斯公式进行推断。设参数 $\theta$的先验分布为$p(\theta)$，在观测数据$\mathcal{D}$后，参数的后验分布为：
$$
p(\theta | \mathcal{D}) = \frac{p(\mathcal{D} | \theta) p(\theta)}{p(\mathcal{D})}\tag{1.2.6}​
$$
其中$p(\mathcal{D} | \theta)$是似然函数，$p(\mathcal{D}) = \int p(\mathcal{D} | \theta) p(\theta) d\theta$是边际似然（或证据）。贝叶斯估计使用后验分布进行预测，而不是点估计。在语言模型中，贝叶斯方法可用于模型选择（通过边际似然）、不确定性量化和小样本学习。

共轭先验是使后验分布与先验分布同分布族的先验选择，这使得贝叶斯推断在计算上更加方便。例如，高斯分布的共轭先验还是高斯分布，二项分布的共轭先验是Beta分布，多项分布的共轭先验是Dirichlet分布。在语言模型中，Beta先验和Dirichlet先验可用于建模词汇概率的不确定性。

变分推断是一类近似贝叶斯推断的方法，它将后验分布的推断转化为优化问题。变分推断假设后验分布可以用某个简单的分布族（如高斯分布）来近似，然后通过最小化近似分布与真实后验分布之间的KL散度来找到最好的近似。在大语言模型中，变分推断被用于VAE的训练、主题模型的推断和某些贝叶斯神经网络方法。

期望传播（Expectation Propagation）是另一种近似推断方法，它通过匹配矩（而不是最小化全局KL散度）来近似后验分布。期望传播在某些情况下比变分推断更准确，特别是当目标分布是高度非高斯的时候。在语言模型的某些应用中，如基于贝叶斯方法的超参数优化，期望传播提供了有用的近似工具。

自助法（Bootstrap）是一种通过重采样来估计统计量方差的非参数方法。基本思想是从原始数据中有放回地抽取与原数据等大的样本，重复多次，计算每次的统计量估计，然后使用这些估计的分布来表征原始统计量的不确定性。在语言模型的评估中，自助法可用于估计困惑度、精确率等指标的置信区间，帮助我们理解模型性能评估的可靠性。

### 1.2.6 大数定律与中心极限定理

大数定律和中心极限定理是概率论中最重要的极限定理，它们描述了大量随机变量之和（或平均值）的渐近行为。这些定理为机器学习中许多方法的合理性提供了理论依据，也指导着我们理解和解释模型训练过程中的各种现象。

大数定律（Law of Large Numbers）指出，当独立同分布的随机变量样本量趋向无穷时，样本均值趋向于随机变量的期望。设$X_1, X_2, \ldots, X_n$是独立同分布的随机变量，期望$E[X_i] = \mu$有限，则样本均值$\bar{X}_n = \frac{1}{n} \sum_{i=1}^n X_i$依概率收敛于$\mu：\lim_{n \to \infty} P(|\bar{X}_n - \mu| > \epsilon) = 0$对任意$\epsilon > 0$成立。

弱大数定律保证样本均值以概率收敛于期望，而强大数定律保证样本均值几乎必然收敛于期望。在机器学习训练中，大数定律解释了为什么使用更大的批量（batch）进行梯度估计时，梯度的方向更加稳定。随着批量大小的增加，梯度估计的方差减小，优化过程变得更加稳定。

在语言模型训练中，我们通常使用随机梯度下降或其变体，每次只使用一小批样本来估计梯度。根据大数定律，当批量大小足够大时，这一小批样本的梯度是整体数据梯度的一个良好近似。然而，当批量太小时，梯度估计的方差较大，可能导致训练过程不稳定或收敛较慢。

中心极限定理（Central Limit Theorem，CLT）是概率论中最深刻的定理之一，它指出大量独立同分布随机变量之和（适当标准化后）趋向于正态分布。设$X_1, X_2, \ldots, X_n$是独立同分布的随机变量，期望$E[X_i] = \mu$有限，方差$\text{Var}(X_i) = \sigma^2$有限，则标准化和$Z_n = \frac{\sum_{i=1}^n X_i - n\mu}{\sigma\sqrt{n}} = \frac{\bar{X}_n - \mu}{\sigma/\sqrt{n}}$的分布趋向于标准正态分布：$\lim_{n \to \infty} P(Z_n \leq z) = \Phi(z)$，其中$\Phi$是标准正态分布的CDF。

中心极限定理的重要性在于它表明正态分布在自然界中无处不在，无论原始随机变量的分布是什么，只要样本量足够大，它们的均值（或和）就近似服从正态分布。在深度学习中，这一性质被用于分析梯度分布、初始化策略和批量归一化的效果。

批量归一化（Batch Normalization）是深度学习中最重要的技术之一，它利用中心极限定理的原理来稳定训练过程。批量归一化对每一层的输入进行标准化，使其均值接近0、方差接近1。从中心极限定理的角度看，当批量大小足够大时，该批量内样本的均值和方差是整体数据均值和方差的良好估计，因此标准化操作是合理的。

在分析神经网络梯度的分布时，中心极限定理提供了重要的洞见。假设网络中有大量独立的噪声源（如随机初始化、Dropout噪声等），则梯度的分布趋向于高斯分布。这种近似在分析神经网络的学习动态、设计优化算法和理解泛化性质时非常有用。

大数定律和中心极限定理也指导着模型评估策略。当我们计算验证集上的性能指标时，该指标是总体性能的一个估计。根据大数定律，验证集越大，这个估计越可靠。根据中心极限定理，我们可以构建置信区间来量化估计的不确定性。在实际应用中，我们需要平衡验证集大小和计算成本，同时理解评估结果的统计显著性。

### 1.2.7 假设检验与模型评估

假设检验是统计推断的重要工具，用于根据样本数据判断关于总体的假设是否成立。在大语言模型的开发和研究中，假设检验被用于比较不同模型的性能、验证改进措施的有效性以及检测数据中的系统性偏差。

假设检验的基本框架包括原假设（$H_0$）和备择假设（$H_1$​）。原假设通常是我们想要拒绝的假设（如"两个模型没有差异"），备择假设是我们想要支持的假设（如"模型A优于模型B"）。我们根据样本数据计算检验统计量，确定在原假设下观察到该统计量或更极端情况的概率（p值）。如果p值小于预先设定的显著性水平（如0.05），则拒绝原假设。

配对t检验是比较两个相关样本均值的常用方法。在语言模型评估中，如果我们使用相同的测试集评估两个模型，配对t检验可以判断两个模型性能的差异是否显著。具体来说，对于每个测试样本，我们计算两个模型的性能差异，然后检验这些差异的均值是否显著不为零。

显著性检验的解读需要谨慎。"统计显著"不等于"实际显著"或"重要"。一个很大的模型可能在某些指标上有统计显著的改进，但改进幅度可能很小以至于在实际应用中可以忽略。p值受样本量影响很大：样本量很大时，即使是微小的差异也可能是统计显著的；样本量很小时，即使很大的差异也可能不显著。

效应量（Effect Size）衡量差异的实际大小，独立于样本量。常用的效应量包括Cohen's d（标准化均值差异）和相关系数。在比较语言模型性能时，报告效应量可以帮助读者理解改进的实际意义。此外，置信区间比p值提供更多信息：它不仅告诉我们差异是否显著，还给出了差异大小的可能范围。

多重比较问题是在进行多个假设检验时需要考虑的重要问题。如果同时检验多个假设，即使所有原假设都为真，至少有一个被拒绝的概率也会大大增加（这是所谓的"多重比较谬误"）。在大语言模型评估中，当我们比较多个模型或在多个测试集上评估时，需要使用适当的多重比较校正方法（如Bonferroni校正或False Discovery Rate控制）来控制总体错误率。

在比较语言模型时，置换检验（Permutation Test）是一种非参数方法，特别适用于样本量不大或分布未知的情况。置换检验通过随机打乱标签来生成置换样本，在原假设下所有排列是等可能的。通过计算真实排列的统计量在置换分布中的位置，可以得到p值。置换检验在比较两个模型在特定测试集上的性能时很有用。

A/B测试是互联网公司和研究机构常用的实验方法，用于比较两个版本（如两个模型或两种策略）的效果。A/B测试的核心是随机分组和控制变量，确保比较的公平性。在大语言模型的在线评估中，A/B测试可以用于评估模型对用户交互的实际影响，如用户满意度、任务完成率等指标。

### 1.2.8 Logits与概率分布的生成

在大语言模型的理论框架中，我们通常不直接建模随机变量的概率分布，而是首先构建一个未归一化的实数向量，称为**Logits**（对数几率）。Logits这一术语源自统计学中的logit函数，它是连接神经网络的线性输出与概率分布的关键桥梁。理解Logits的本质，对于掌握语言模型的生成机制和优化原理至关重要。

设$V$为离散随机变量$X$的状态空间大小，在大语言模型中即为词汇表的大小。定义Logits向量$\mathbf{z} \in \mathbb{R}^V$，其中每个分量$z_i \in (-\infty, +\infty)$代表模型对第$i$个词元的原始置信度评分。Logits向量具有两个显著特点：第一，$z_i$的取值范围是整个实数轴，既可以为正也可以为负，这使其不受概率公理的限制；第二，Logits的分量之间是相对的，其绝对数值本身并不具有直接的概率意义，只有经过适当的变换后才能转化为有效的概率分布。

从Logits到概率分布的转换通过**Softmax函数**实现。Softmax函数将$\mathbb{R}^V$空间中的向量映射到概率单纯形$\Delta^{V-1}$上，定义为：

$$
p_i = P(X = i) = \text{Softmax}(\mathbf{z})_i = \frac{\exp(z_i)}{\sum_{j=1}^{V} \exp(z_j)}\tag{1.2.7}
$$

Softmax函数的分母对所有分子的指数项进行归一化，确保输出的概率分布满足归一性条件$\sum_{i=1}^{V} p_i = 1$。指数函数$\exp(\cdot)$的非负性保证了输出概率的非负性。同时，Softmax函数具有"软最大化"的特性：它不仅选择概率最高的类别（类似argmax操作），还为所有类别分配非零的概率值，只是概率质量的分布会根据Logits的相对大小进行调整。这种特性使得模型能够在生成过程中保持一定的随机性和多样性，而非总是选择最确定的答案。

在大语言模型中，Logits的生成过程如下：输入序列经过多层Transformer架构的变换后，在输出层产生一个与词汇表大小相同的Logits向量$\mathbf{z}$。这个向量随后经过Softmax变换，得到词汇表上各词元的生成概率分布$P(y_t | y_{<t})$，模型再根据这个分布进行词元的采样或选择。值得注意的是，在实际实现中，为了提高数值稳定性，通常直接计算Log-Softmax：$\log \text{Softmax}(\mathbf{z})_i = z_i - \log \sum_{j=1}^{V} \exp(z_j)$，这样可以避免Softmax计算中指数运算可能导致的数值溢出问题。

从优化的视角审视，模型输出Logits而非直接预测概率具有深刻的理论依据。首先，Logits的定义域是整个实数空间，这使得梯度更新不受概率边界约束的限制，优化过程更加自由和稳定。其次，当Logits与交叉熵损失函数结合使用时，损失函数关于Logits的梯度具有极其简洁的形式：设$p_i = \text{Softmax}(\mathbf{z})_i$为预测概率，$y_i$为真实标签（one-hot编码），则交叉熵损失$L = -\sum_{i=1}^{V} y_i \log p_i$关于$z_k$的偏导数为$\frac{\partial L}{\partial z_k} = p_k - y_k$。这个"预测减真实"的梯度形式具有优美的残差结构，不仅计算高效，还能有效避免深度神经网络中常见的梯度消失问题，是现代大规模语言模型能够稳定训练的重要数学基础。

在实际应用中，可以通过温度参数$T$来调节Softmax的"锐度"，修改后的公式为$p_i = \frac{\exp(z_i / T)}{\sum_{j=1}^{V} \exp(z_j / T)}$。当$T > 1$时，概率分布变得更加平坦，增加了生成的多样性；当$T < 1$时，分布变得更加尖锐，模型倾向于选择高概率的词元。Top-k采样和Top-p采样等解码策略也都是在概率分布层面进行操作的各种启发式方法，它们的效果最终都可以追溯到Logits向量的相对结构和Softmax变换的特性。