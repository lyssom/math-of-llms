---
layout: default
title: 大模型中的数学
---
# Wir müssen wissen, wir werden wissen --David Hilbert
#####                               我们必须知道，我们终将知道 --大卫·希尔伯特

## 第一章 线性代数基础
-  [[1.1 线性代数与张量运算]]
-  [[1.2 概率论与统计]]
-  [[1.3 微积分与优化基础]]
## 第二章 前馈网络数学
- [[2.1 神经元的数学模型]]
- [[2.2 神经网络的矩阵形式]]
- [[2.3 前向传播的数学本质]]
- [[2.4 反向传播梯度推导]]
## 第三章 激活函数与非线性数学
- [[3.1 激活函数的数学角色]]
- [[3.2 导数推导与梯度特性]]
- [[3.3 梯度饱和与梯度爆炸的数学根源]]
## 第四章 损失函数数学
- [[4.1 均方误差（MSE）的数学基础与几何解释]]
- [[4.2 交叉熵的概率论推导]]
- [[4.3 损失函数数学结构对比]]
- [[4.4 InfoNCE与注意力的Softmax统一]]
- [[4.5 大语言模型中的损失函数]]
- [[4.6 损失函数的优化性质]]
## 第五章 注意力机制数学
- [[5.1 Scaled Dot-Product Attention 的数学公式]]
- [[5.2 Query、Key、Value的矩阵表示与变换]]
- [[5.3 多头注意力的矩阵推导与表达能力分析]]
- [[5.4 注意力如何建模长程依赖]]
- [[5.5 注意力矩阵的谱性质与低秩结构]]
- [[5.6 注意力机制的变体]]
## 第六章 位置编码数学
- [[6.1 正弦余弦位置编码的数学定义与推导]]
- [[6.2 频率空间的数学分析]]
- [[6.3 可学习位置编码的矩阵性质]]
- [[6.4 Rotary Position Embedding（RoPE）的复数、群论完整推导]]


TBD...