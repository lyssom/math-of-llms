---
layout: default
title: 大模型中的数学
---
# Wir müssen wissen, wir werden wissen --David Hilbert
#####                               我们必须知道，我们终将知道 --大卫·希尔伯特

## 第一章 线性代数基础
-  [[1.1 线性代数与张量运算]]
-  [[1.2 概率论与统计]]
-  [[1.3 微积分与优化基础]]
## 第二章 前馈网络数学
- [[2.1 神经元的数学模型]]
- [[2.2 神经网络的矩阵形式]]
- [[2.3 前向传播的数学本质]]
- [[2.4 反向传播梯度推导]]
## 第三章 激活函数与非线性数学
- [[3.1 激活函数的数学角色]]
- [[3.2 导数推导与梯度特性]]
- [[3.3 梯度饱和与梯度爆炸的数学根源]]
## 第四章 损失函数数学
- [[4.1 均方误差（MSE）的数学基础与几何解释]]
- [[4.2 交叉熵的概率论推导]]
- [[4.3 损失函数数学结构对比]]
- [[4.4 InfoNCE与注意力的Softmax统一]]
- [[4.5 大语言模型中的损失函数]]
- [[4.6 损失函数的优化性质]]
## 第五章 注意力机制数学
- [[5.1 Scaled Dot-Product Attention 的数学公式]]
- [[5.2 Query、Key、Value的矩阵表示与变换]]
- [[5.3 多头注意力的矩阵推导与表达能力分析]]
- [[5.4 残差连接与归一化]]
- [[5.5 注意力如何建模长程依赖]]
- [[5.6 注意力矩阵的谱性质与低秩结构]]
- [[5.7 注意力机制的变体]]
## 第六章 位置编码数学
- [[6.1 正弦余弦位置编码的数学定义与推导]]
- [[6.2 频率空间的数学分析]]
- [[6.3 可学习位置编码的矩阵性质]]
- [[6.4 Rotary Position Embedding（RoPE）的复数、群论完整推导]]
## 第七章 条件计算与稀疏模型：混合专家方法
- [[7.1 MoE概述与门控机制]]
- [[7.2 专家网络与负载均衡]]
- [[7.3 训练与推理优化]]
## 第八章 强化学习
- [[8.1 强化学习基础与马尔可夫决策过程]]
- [[8.2 策略梯度与Actor-Critic方法]]
- [[8.3 PPO算法与大模型训练]]
## 第九章 梯度流与优化数学
- [[9.1 梯度协方差矩阵]]
- [[9.2 梯度消失与梯度爆炸的数学条件]]
- [[9.3 梯度裁剪与正则化]]
## 第十章 正则化与归一化数学
- [[10.1 常见归一化方法的数学表述]]
- [[10.2 Dropout的期望保持性质]]
- [[10.3 正则化对梯度与损失的影响]]
## 第十一章 矩阵与张量分解
- [[11.1 矩阵与张量分解：SVD、Tucker、CP分解]]
- [[11.2 大模型中低秩近似的数学依据]]
- [[11.3 注意力矩阵的低秩结构]]
## 第十二章 概率视角下的大模型
- [[12.1 自回归公式（链式法则）]]
- [[12.2 最大似然与交叉熵的详细推导]]
- [[12.3 标度律]]
## 第十三章 动态系统与训练稳定性
- [[13.1 离散时间动态系统的数学基础]]
- [[13.2 Jacobian、Hessian 的稳定性分析]]
- [[13.3 收敛性、震荡、周期行为]]
## 第十四章 信息论视角
- [[14.1 信息熵与互信息]]
- [[14.2 正则化与信息瓶颈]]
- [[14.3 注意力机制与信息流量]] 
