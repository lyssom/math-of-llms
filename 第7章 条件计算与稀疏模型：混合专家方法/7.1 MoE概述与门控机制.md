# 第7章 条件计算与稀疏模型：混合专家方法
## 7.1 MoE概述与门控机制
混合专家（Mixture of Experts，MoE）是深度学习领域最具影响力的架构创新之一，它从根本上重新思考了模型容量与计算效率之间的关系。传统的稠密模型在处理任何输入时都会激活全部参数，这种"全开"的设计虽然简单直观，但随着模型规模的增长，计算成本呈平方级上升，迅速达到硬件能力的瓶颈。MoE架构引入了一种革命性的条件计算范式：模型拥有海量的专业参数，但每个输入只动态选择其中一小部分参与计算。这种"按需激活"的策略打破了参数量与计算量之间的刚性绑定，使得在有限计算预算下训练超大规模模型成为可能。本节将系统阐述MoE的核心理念、数学原理和门控机制的设计，为深入理解这一架构奠定坚实的理论基础。
### 7.1.1 MoE核心思想：条件计算

条件计算（Conditional Computation）的核心理念源于对计算资源优化配置的理论洞察。在传统的神经网络中，无论是输入样本的具体内容如何，整个网络的所有参数都会被激活并参与计算。设输入向量为 $\mathbf{x} \in \mathbb{R}^d$，传统稠密模型的输出可以表示为 $\mathbf{y} = f(\mathbf{x}; \theta)$，其中 $f$ 是由参数 $\theta$ 定义的神经网络函数。无论输入 $\mathbf{x}$ 的内容如何复杂或简单，参数 $\theta$ 中的每一个元素都会被用于计算，这种"一刀切"的计算模式在资源效率上存在显著浪费。事实上，不同类型的输入往往需要模型的不同"专业知识"来处理：处理数学问题的输入可能主要需要模型的数学推理能力，处理创意写作的输入可能主要需要模型的生成表达能力，而处理代码补全的输入则需要模型的程序理解能力。

条件计算的核心洞见在于，如果能够根据输入内容动态地决定应该使用哪些参数，就可以避免对无关参数的无效计算，从而在相同的计算预算下支持更大的模型容量。从数学上看，条件计算将传统的确定性函数映射 $f: \mathcal{X} \to \mathcal{Y}$ 扩展为条件函数族 $\{f_i: \mathcal{X} \to \mathcal{Y}\}_{i=1}^{K}$，并引入一个路由函数 $R: \mathcal{X} \to \{1, \ldots, K\}$ 决定为每个输入选择哪个函数。模型的最终输出为 $f_{R(\mathbf{x})}(\mathbf{x})$，即根据输入 $\mathbf{x}$ 选择的特定函数 $f_{R(\mathbf{x})}$ 的输出。这种条件化的计算模式意味着，虽然模型定义了 $K$ 个不同的函数（每个都可以是一个复杂的神经网络），但每次前向传播只计算其中一个，从而将计算量从 $O(\sum_{i=1}^{K} \text{cost}(f_i))$ 降低到 $O(\text{cost}(f_{R(\mathbf{x})}))$。
MoE将条件计算的思想具体化为"专家网络"的集合与"门控机制"的协调配合。专家网络（Experts）是模型中的一组子网络，每个专家可以视为一个专门处理特定类型输入的"专业模块"。设共有 $K$ 个专家网络，记为 $\mathcal{E} = \{E_1, E_2, \ldots, E_K\}$，其中每个专家 $E_i$ 是一个参数化为 $\theta_i$ 的神经网络。门控机制（Gating Network）则是MoE架构的决策中心，它接收输入 $\mathbf{x}$，输出一组权重 $G(\mathbf{x}) = (g_1(\mathbf{x}), g_2(\mathbf{x}), \ldots, g_K(\mathbf{x}))$，决定每个专家对当前输入的贡献程度。模型的最终输出是专家输出的加权组合：$\mathbf{y} = \sum_{i=1}^{K} g_i(\mathbf{x}) \cdot E_i(\mathbf{x})$。
稀疏激活是MoE区别于其他架构的关键特征。在标准的MoE设置中，门控函数的输出虽然覆盖所有 $K$ 个专家，但只有权重最高的 $K'$ 个专家（通常 $K' \ll K$）会被实际激活并参与计算。对于权重低于阈值的专家，其参数不会被访问，相关的计算和内存访问被完全跳过。这种稀疏性意味着，即使模型拥有 $K$ 个专家，推理时每个输入实际只需要计算 $K'$ 个专家的计算量。当 $K'$ 固定而 $K$ 可以增长时，模型的参数规模可以大幅扩展，而推理成本仅线性于 $K'$ 而非 $K$。数学上，稀疏激活可以表示为引入一个选择函数 $\text{TopK}(\cdot)$，只保留权重最大的 $K'$ 个分量，其余分量被置零或完全忽略，从而将计算复杂度从 $O(K)$ 降低到 $O(K')$。
### 7.1.2 稠密模型与MoE的对比分析
理解MoE的独特价值，需要将其与传统的稠密（Dense）模型进行系统性的对比分析。这种对比不仅体现在计算效率上，更深入到模型容量、表达能力、训练动态和部署策略等多个维度，揭示了两种架构设计哲学的根本差异。
从参数利用效率的角度分析，稠密模型和MoE模型对参数的使用方式存在本质区别。设模型的隐藏层维度为 $d$，前馈网络的中间维度为 $d_{\text{ff}}$，则一个标准Transformer前馈层的计算可以表示为：
$$\mathbf{h}_{\text{out}} = \mathbf{W}_2 \cdot \sigma(\mathbf{W}_1 \cdot \mathbf{h}_{\text{in}} + \mathbf{b}_1) + \mathbf{b}_2$$
其中 $\mathbf{h}_{\text{in}} \in \mathbb{R}^d$ 是输入激活，$\mathbf{W}_1 \in \mathbb{R}^{d_{\text{ff}} \times d}$ 和 $\mathbf{W}_2 \in \mathbb{R}^{d \times d_{\text{ff}}}$ 是权重矩阵，$\sigma$ 是激活函数（如GELU或ReLU）。在这个标准的前馈层中，权重矩阵 $\mathbf{W}_1$ 和 $\mathbf{W}_2$ 的所有元素都会被用于计算每个输入，这意味着 $d \cdot d_{\text{ff}} + d_{\text{ff}} \cdot d = 2d \cdot d_{\text{ff}}$ 个参数被完全利用来完成前向传播。
在MoE架构中，前馈层被替换为MoE层，其数学形式为：
$$\mathbf{h}_{\text{out}} = \sum_{i=1}^{K} g_i(\mathbf{x}) \cdot E_i(\mathbf{h}_{\text{in}})$$
其中 $E_i$ 是第 $i$ 个专家的前馈网络，$g_i(\mathbf{x})$ 是由门控机制分配的概率权重。对于Top-K稀疏路由，假设 $K'=2$，则输出退化为仅对权重最高的两个专家求和：
$$\mathbf{h}_{\text{out}} = \sum_{i \in S(\mathbf{x})} g_i^{\text{sparse}}(\mathbf{h}_{\text{in}}) \cdot E_i(\mathbf{h}_{\text{in}})$$
其中 $S(\mathbf{x})$ 是门控权重最大的 $K'$ 个专家的索引集合。这种稀疏激活模式意味着，尽管模型定义了 $K$组权重 $\{\mathbf{W}_1^{(i)}, \mathbf{W}_2^{(i)}\}_{i=1}^{K}$，每个输入只使用其中 $K'$ 组进行计算。
从计算复杂度的角度分析，稠密模型和MoE模型遵循截然不同的规模缩放规律。标准Transformer层的计算量主要来自两个矩阵乘法：注意力机制的 $QK^\top$ 运算（$O(S^2 d)$，其中 $S$ 是序列长度）和前馈网络的矩阵乘法（$O(d \cdot d_{\text{ff}})$）。对于 $L$ 层模型，总计算量约为 $O(L \cdot (S^2 d + d \cdot d_{\text{ff}}))$。如果将模型规模扩大为隐藏维度 $4d$ 的配置，计算量将增加约16倍，这在大规模训练场景下是难以承受的计算负担。
在MoE模型中，设专家数量为 $K$，每个专家的前馈网络维度为 $d_e$（通常 $d_e \ll d_{\text{ff}}$），激活的专家数为 $K'$，则每层前馈网络的计算量约为 $O(K' \cdot d \cdot d_e)$。由于 $d_e$ 可以远小于 $d_{\text{ff}}$，且 $K'$ 固定（通常为1或2），即使 $K$ 很大（如64或128），MoE层的计算量也可以保持在与稠密层相当的水平，同时参数量扩展到 $O(K \cdot d \cdot d_e)$。这种参数量与计算量的解耦是MoE最核心的优势：它使得在相同的计算预算下，训练拥有数倍甚至数十倍参数量的大模型成为可能。
稠密模型与MoE模型的核心差异可以总结为下表：

| 特性    | 稠密模型     | MoE模型                             |
| ----- | -------- | --------------------------------- |
| 参数使用  | 所有参数全部激活 | 仅激活部分参数（Top-K）                    |
| 计算复杂度 | $O(d^2)$ | $O(K' \cdot d_e^2)$，其中 $K' \ll K$ |
| 模型容量  | 受限于计算预算  | 可扩展至超大规模                          |
| 门控机制  | 无        | 需要学习路由策略                          |
| 负载均衡  | 自动均衡     | 需要辅助损失正则化                         |
从模型表达能力的角度分析，MoE架构引入了独特的函数逼近特性。数学上，一个具有 $K$ 个专家的MoE模型可以表示为函数：

$$f_{\text{MoE}}(\mathbf{x}) = \sum_{i=1}^{K} g_i(\mathbf{x}) \cdot E_i(\mathbf{x})$$
这种表示形式本质上是一种软混合（Soft Mixing）或专家选择的组合。理论上，如果每个专家 $E_i$ 是一个通用逼近器（如足够宽的神经网络），则MoE模型的表达能力可以达到或超过同等容量的稠密模型。更重要的是，MoE的组合结构提供了一种"分而治之"的学习范式：不同的专家可以专门学习数据分布的不同区域或不同类型的模式，从而实现更加精细的函数逼近。研究表明，在语言建模等任务上，MoE模型相比同等计算量的稠密模型能够取得显著的性能提升，这验证了条件计算范式的有效性。
然而，MoE架构也带来了稠密模型中不存在的新挑战。负载均衡（Load Balancing）问题是其中最突出的一个：由于门控机制倾向于将相似输入分配给相似的专家，如果训练不当，可能出现少数专家承担大部分计算负载，而多数专家几乎不被激活的情况。这种不平衡不仅浪费了模型的大部分参数，还可能导致这些"被冷落"的专家在训练过程中无法得到充分更新，形成恶性循环。数学上，负载均衡可以通过监控专家分配概率的方差来量化：如果专家分配概率的方差很大，说明存在严重的负载不均衡，需要引入辅助损失来正则化门控网络。
### 7.1.3 缩放定律的数学解释
缩放定律（Scaling Laws）是理解大语言模型能力增长规律的重要理论框架，而MoE架构之所以具有吸引力，正是因为它能够改变传统的缩放关系，使得在相同计算预算下获得更强的模型成为可能。深入理解缩放定律的数学本质，对于设计和训练高效的MoE模型至关重要。
传统的Transformer语言模型遵循经验性的缩放定律：测试损失 $\mathcal{L}$ 与模型参数量 $N$、训练数据量 $D$ 和计算量 $C$ 之间存在幂律关系：
$$\mathcal{L}(N, D, C) = A \cdot N^{-\alpha_N} + B \cdot D^{-\alpha_D} + C \cdot C^{-\alpha_C} + L_{\infty}$$
其中 $A, B, C$ 是比例常数，$\alpha_N, \alpha_D, \alpha_C$ 是标度指数，$L_{\infty}$ 是不可约损失（主要由数据的内在熵决定）。这个经验公式表明，要降低测试损失，需要不成比例地增加模型规模、训练数据或计算资源。例如，如果 $\alpha_N = 0.1$，则模型规模翻倍只能使损失降低约 $7\%$；要使损失减半，需要将模型规模增加约 $2^{1/\alpha_N} = 2^{10} = 1024$ 倍。
MoE架构通过改变参数利用效率来突破这一缩放瓶颈。在稠密模型中，参数量 $N$ 与计算量 $C$ 成正比（$C \propto N$），这意味着增加参数必须同时增加等比例的计算成本。设 $N_{\text{dense}}$ 是稠密模型的参数量，$C_{\text{dense}}$ 是对应的计算量，则 $C_{\text{dense}} \approx \kappa \cdot N_{\text{dense}}$，其中 $\kappa$ 是每参数的浮点运算数。缩放定律可以重写为仅关于计算量的函数：
$$\mathcal{L}_{\text{dense}}(C) = A' \cdot C^{-\alpha_N} + B' \cdot C^{-\alpha_D} + L_{\infty}$$
在MoE模型中，参数量 $N_{\text{MoE}}$ 与计算量 $C_{\text{MoE}}$ 之间的关系被打破。设MoE模型有 $K$ 个专家，每个专家的参数量为 $N_e$，则总参数量 $N_{\text{MoE}} = K \cdot N_e$。由于每个输入只激活 $K'$ 个专家，有效计算量 $C_{\text{MoE}} \approx \kappa \cdot K' \cdot N_e = \frac{K'}{K} \cdot \kappa \cdot N_{\text{MoE}} = \frac{K'}{K} \cdot C_{\text{dense}}$。这意味着，对于相同规模的模型，MoE的计算量是稠密模型的 $\frac{K'}{K}$ 倍；或者说，在相同的计算预算 $C$ 下，MoE模型可以支持的参数量为：
$$N_{\text{MoE}} = \frac{K}{K'} \cdot \frac{C}{\kappa}$$
代入缩放定律，MoE模型的预期损失为：
$$\mathcal{L}_{\text{MoE}}(C) = A \cdot \left(\frac{K}{K'} \cdot \frac{C}{\kappa}\right)^{-\alpha_N} + B \cdot D^{-\alpha_D} + L_{\infty} = A \cdot \left(\frac{K}{K'}\right)^{-\alpha_N} \cdot C^{-\alpha_N} + B \cdot D^{-\alpha_D} + L_{\infty}$$
与稠密模型相比，MoE模型的损失多了一个常数因子 $\left(\frac{K}{K'}\right)^{-\alpha_N}$。由于 $\alpha_N > 0$，这个因子小于1，说明在相同计算预算下，MoE模型能够取得更低的损失。这个数学推导揭示了MoE架构的核心价值：通过增加参数量（牺牲参数存储和通信效率）来换取计算效率的提升，从而在固定的计算预算下获得更强的模型。
Chinchilla论文进一步精细化了计算最优缩放的理论，提出了在固定计算预算下，参数量 $N$ 和数据量 $D$ 应该按比例同时增长的观点。具体而言，计算最优的缩放关系为 $N \propto D$，这意味着随着计算预算的增加，模型规模和数据规模应该同步扩大。对于MoE模型，这意味着不仅要增加专家数量 $K$，还要相应地增加训练数据量 $D$，以确保每个专家都能得到充分的学习。数学上，计算最优的MoE配置满足：
$$N_{\text{opt}} = \frac{C}{\kappa \cdot K'} \cdot \sqrt{\frac{A}{B} \cdot \frac{\alpha_D}{\alpha_N}}$$
这个公式为设计MoE模型的超参数提供了理论指导。在实际应用中，$\alpha_N$ 和 $\alpha_D$ 的值通常通过小规模实验拟合得到，然后应用于预测更大规模模型的配置。
#### 7.1.4 稀疏激活的效率优势
稀疏激活是MoE架构实现计算效率提升的关键机制，其数学本质是通过减少每次前向传播中实际参与的参数数量来降低计算成本。深入理解稀疏激活的效率优势，需要从计算复杂度、内存带宽和硬件利用率等多个角度进行分析。
设MoE模型有 $K$ 个专家，每个专家的参数量为 $N_e$，激活的专家数为 $K'$，则稀疏度（Sparsity）定义为未被激活的专家比例：
$$S = 1 - \frac{K'}{K}$$
当 $K=64$ 且 $K'=2$ 时，稀疏度 $S = 1 - \frac{2}{64} = 96.875\%$，这意味着超过 $96\%$ 的专家参数在每次前向传播中不会被访问。这种高稀疏度带来的效率优势是显著的：模型的总参数量是 $K \cdot N_e$，但实际计算量仅为 $K' \cdot N_e$，计算效率相对于稠密模型提升了 $K/K'$ 倍。
从计算复杂度的角度分析，假设每个专家的前馈网络需要进行两次矩阵乘法（对应 $\mathbf{W}_1$ 和 $\mathbf{W}_2$），则单次前向传播的总计算量（以浮点运算次数计）为：
$$\text{FLOPs}_{\text{dense}} = 2 \cdot d \cdot d_{\text{ff}} + 2 \cdot d_{\text{ff}} \cdot d = 4 \cdot d \cdot d_{\text{ff}}$$
对于MoE模型，激活 $K'$ 个专家的计算量为：
$$\text{FLOPs}_{\text{MoE}} = 2 \cdot d \cdot d_e + 2 \cdot d_e \cdot d = 4 \cdot d \cdot d_e$$
其中 $d_e$ 是每个专家的隐藏维度（通常 $d_e < d_{\text{ff}}$）。设 $d_e = d_{\text{ff}} / g$（$g$ 是专家维度缩减因子），则：
$$\text{FLOPs}_{\text{MoE}} = \frac{4 \cdot d \cdot d_{\text{ff}}}{g}$$
如果设置 $K'=2$ 且 $g=4$，则单专家计算量是稠密模型的 $1/4$，但由于激活两个专家，总计算量为稠密模型的 $2/4 = 1/2$。与此同时，模型参数量是稠密模型的 $K/g = 64/4 = 16$ 倍。这意味着，在相同的计算预算下，MoE模型可以拥有16倍于稠密模型的参数量。
稀疏激活的另一个重要优势体现在内存带宽利用率上。现代处理器的性能瓶颈往往不在于计算单元的算力，而在于内存带宽——将数据从主存移动到计算单元需要消耗大量时间和能量。在MoE的稀疏激活模式下，未被选中的专家的权重根本不需要被加载到计算单元中，这显著减少了对内存带宽的需求。数学上，内存访问量与激活的参数量成正比，稀疏激活将其从 $N_{\text{total}}$ 降低到 $N_e \cdot K'$，内存带宽效率相应提升了 $K/K'$ 倍。
然而，稀疏激活也带来了新的挑战。最主要的问题是稀疏访问模式与现代硬件的优化方向不完全匹配。现代GPU和TPU针对稠密矩阵运算进行了高度优化，具有极高的吞吐量和内存合并访问模式。稀疏激活导致的非连续内存访问可能无法充分利用硬件的并行计算能力。为了缓解这个问题，实际实现中通常采用"专家分块"（Expert Tiling）策略：将每个专家的参数分成多个小块，在连续的计算中依次处理不同专家的相同位置，以改善内存访问的局部性。
专家并行的实现是分布式训练MoE模型的关键技术。在专家并行策略下，不同的专家被分配到不同的计算设备上，每个设备只存储和计算分配给自己的专家。设总共有 $M$ 个设备，第 $m$ 个设备负责专家 $E_{(m-1) \cdot \lceil K/M \rceil + 1}$ 到 $E_{m \cdot \lceil K/M \rceil}$，则每个设备的参数量约为 $N_e \cdot \lceil K/M \rceil$。由于每个输入只需要 $K'$ 个专家的输出，设备间通信（All-to-All）成为性能的关键瓶颈。高效的专家并行实现需要最小化设备间数据传输量，并通过流水线重叠计算和通信。
#### 7.1.5 Softmax门控函数
门控机制是MoE架构的核心决策模块，其设计直接决定了模型的稀疏激活模式和训练效率。Softmax门控函数是最基础也是最广泛使用的门控设计，其数学形式简洁优雅，同时具有良好的可微性，便于通过反向传播进行优化。
门控函数 $G: \mathbb{R}^d \to \mathbb{R}^K$ 接收输入特征 $\mathbf{x}$，输出一个 $K$ 维的权重向量 $G(\mathbf{x}) = (g_1(\mathbf{x}), g_2(\mathbf{x}), \ldots, g_K(\mathbf{x}))$。Softmax门控的数学定义为：
$$G(\mathbf{x}) = \text{Softmax}(\mathbf{W}\mathbf{x} + \mathbf{b})$$
其中 $\mathbf{W} \in \mathbb{R}^{K \times d}$ 是可学习的权重矩阵，$\mathbf{b} \in \mathbb{R}^K$ 是偏置向量。Softmax函数的逐分量形式为：
$$g_i(\mathbf{x}) = \frac{\exp((\mathbf{W}\mathbf{x} + \mathbf{b})_i)}{\sum_{j=1}^{K} \exp((\mathbf{W}\mathbf{x} + \mathbf{b})_j)}$$
这个定义确保了输出权重满足概率分布的基本性质：对所有 $i$，$g_i(\mathbf{x}) \geq 0$，且 $\sum_{i=1}^{K} g_i(\mathbf{x}) = 1$。Softmax函数的核心特性是它将任意实数向量转换为有效的概率分布，同时保持原始得分的相对顺序，得分最高的专家仍然获得最高的权重。
从优化的角度看，Softmax门控函数是完全可微的。权重 $g_i(\mathbf{x})$ 关于门控网络参数 $\mathbf{W}$ 和 $\mathbf{b}$ 的梯度可以通过链式法则计算。设 $s_i(\mathbf{x}) = (\mathbf{W}\mathbf{x} + \mathbf{b})_i$ 是原始门控得分，则：
$$\frac{\partial g_i(\mathbf{x})}{\partial \mathbf{W}} = \frac{\partial g_i(\mathbf{x})}{\partial s_i(\mathbf{x})} \cdot \frac{\partial s_i(\mathbf{x})}{\partial \mathbf{W}}$$
其中 $\frac{\partial s_i(\mathbf{x})}{\partial \mathbf{W}} = \mathbf{x}^\top$（对对应行），而 Softmax 的雅可比矩阵为：
$$\frac{\partial g_i}{\partial s_j} = g_i (\delta_{ij} - g_j)$$
这里 $\delta_{ij}$ 是克罗内克函数（当 $i=j$ 时为1，否则为0）。这种雅可比结构表明，门控权重不仅取决于自身得分的梯度，还受到其他专家得分的间接影响，这是Softmax归一化带来的必然结果。
简单的线性Softmax门控存在明显的局限性：它只能学习输入空间的线性划分，无法捕捉复杂的非线性决策边界。设输入空间中存在两个不同类型的输入簇 $\mathcal{X}_1$ 和 $\mathcal{X}_2$，简单的线性门控可能无法找到一条直线将两个簇的路由决策分开，因为两个簇在输入空间中可能以非线性方式交织。在实践中，这种简单的门控往往导致门控权重高度集中于少数专家，使得稀疏激活退化为确定性选择，失去了MoE架构的优势。
为了增强门控的表达能力，实际应用中通常采用更复杂的门控设计。一种常见的方法是在线性变换后引入非线性激活，构建两层门控网络：
$$G(\mathbf{x}) = \text{Softmax}(\mathbf{W}_2 \cdot \text{ReLU}(\mathbf{W}_1 \mathbf{x} + \mathbf{b}_1) + \mathbf{b}_2)$$
其中 $\mathbf{W}_1 \in \mathbb{R}^{H \times d}$ 是第一层权重（$H$ 是隐藏维度），$\mathbf{W}_2 \in \mathbb{R}^{K \times H}$ 是第二层权重。这种非线性门控可以学习输入空间的非线性划分，使专家分配更加多样化。隐藏维度 $H$ 越大，门控的表达能力越强，但参数量和过拟合风险也相应增加。
另一种增强门控能力的方法是引入输入的部分先验信息。例如，可以根据输入文本的语言、主题或长度等元特征来初始化或偏置门控决策。这种条件门控的数学形式为：
$$G(\mathbf{x}) = \text{Softmax}(\mathbf{W}\mathbf{x} + \mathbf{V}\mathbf{c}(\mathbf{x}) + \mathbf{b})$$
其中 $\mathbf{c}(\mathbf{x})$ 是从输入 $\mathbf{x}$ 中提取的先验特征，$\mathbf{V}$ 是对应的投影矩阵。这种设计在处理多语言、多任务场景时特别有效，因为它可以强制某些专家处理特定类型的输入，从而促进专家的专业化。
### 7.1.6 Top-K稀疏路由
在实际的大规模MoE实现中，稀疏激活通过Top-K路由策略实现，这是一种在保持门控可学习性的同时实现高效计算的关键技术。Top-K路由的数学原理和实现细节对于理解MoE的工作机制至关重要。
Top-K路由的核心思想是只选择门控权重最大的 $K'$ 个专家参与计算。设 $K'$ 是预定义的激活专家数量（通常 $K'=1$ 或 $K'=2$），则Top-K选择操作可以数学化为：
$$S(\mathbf{x}) = \underset{S \subseteq \{1, \ldots, K\}, |S|=K'}{\arg\max} \sum_{i \in S} s_i(\mathbf{x})$$
其中 $s_i(\mathbf{x}) = (\mathbf{W}\mathbf{x} + \mathbf{b})_i$ 是专家 $i$ 的原始门控得分。$S(\mathbf{x})$ 返回得分最高的 $K'$ 个专家的索引集合，这个选择是确定性的（相同的输入总是产生相同的输出）。
Top-K路由的稀疏门控权重需要重新归一化，以确保激活专家的权重和为1。设 $S(\mathbf{x}) = \{i_1, i_2, \ldots, i_{K'}\}$ 是选中的专家索引，则稀疏门控权重为：

$$g_i^{\text{sparse}}(\mathbf{x}) = \begin{cases} \frac{\exp(s_i(\mathbf{x}))}{\sum_{j \in S(\mathbf{x})} \exp(s_j(\mathbf{x}))} & \text{if } i \in S(\mathbf{x}) \\ 0 & \text{otherwise} \end{cases}$$
这种归一化确保了 $\sum_{i \in S(\mathbf{x})} g_i^{\text{sparse}}(\mathbf{x}) = 1$，保持了输出的归一化性质。
在实现中，Top-K操作通常结合一个"掩码"步骤来高效地实现稀疏计算。设原始Softmax输出为 $\mathbf{g}(\mathbf{x}) \in \mathbb{R}^K$，Top-K掩码向量为 $\mathbf{m}(\mathbf{x}) \in \{0, 1\}^K$（对应Top-K位置为1，其余为0），则稀疏门控可以写为：
$$\mathbf{g}^{\text{sparse}}(\mathbf{x}) = \frac{\mathbf{g}(\mathbf{x}) \odot \mathbf{m}(\mathbf{x})}{\sum_{j=1}^{K} g_j(\mathbf{x}) \cdot m_j(\mathbf{x})}$$
其中 $\odot$ 表示逐元素乘法。掩码 $\mathbf{m}(\mathbf{x})$ 的计算可以通过对 $s_i(\mathbf{x})$ 进行排序并取前 $K'$ 个位置来实现，现代深度学习框架提供了高度优化的Top-K操作原语。
Top-K选择的一个微妙之处在于它破坏了梯度流的连续性。由于Top-K操作本身是不可微的（输出相对于输入的梯度几乎处处为零，除了在边界情况），直接使用Top-K会导致梯度无法反向传播到门控网络。为了解决这个问题，实际实现中通常采用"软Top-K"或"可微Top-K"的技巧：在前向传播时使用硬Top-K选择，在反向传播时使用软梯度近似。
一种常用的技巧是使用Gumbel-Softmax来近似Top-K选择。Gumbel-Softmax分布为：
$$g_i^{\text{Gumbel}}(\mathbf{x}) = \frac{\exp((s_i(\mathbf{x}) + g_i) / \tau)}{\sum_{j=1}^{K} \exp((s_j(\mathbf{x}) + g_j) / \tau)}$$
其中 $g_i = -\log(-\log(u_i))$ 是从Gumbel分布采样的噪声，$\tau$ 是温度参数。当 $\tau \to 0$ 时，Gumbel-Softmax收敛于One-Hot分布（近似硬Top-K）；当 $\tau \to \infty$ 时，Gumbel-Softmax收敛于均匀分布。通过在训练时使用Gumbel-Softmax（$\tau > 0$）并在推理时切换到硬Top-K（$\tau \to 0$），可以实现可学习的稀疏路由。
Top-K选择（$K'$ 的值）显著影响模型的效率与效果。当 $K'=1$ 时，每个输入只激活一个专家，这提供了最大的计算效率，但也可能导致专家分配的不连续性：当输入特征发生微小变化时，可能从一个专家跳转到另一个完全不同的专家，输出可能发生剧烈变化。$K'=2$ 的设置允许每个输入由两个专家共同处理，增加了输出的平滑性，但也意味着推理时需要计算两个专家，计算成本翻倍。在实践中，$K'=1$ 是最常见的设置，因为它在效率和效果之间取得了良好的平衡。
### 7.1.7 噪声加入与均匀负载
噪声加入（Noisy Top-K Gating）是稳定训练和促进专家多样性的关键技巧，其数学原理和实际效果对于理解MoE的训练动态至关重要。噪声的引入解决了门控网络可能陷入局部最优的问题，使得专家能够更均匀地分配负载，从而充分利用模型的全部容量。
门控网络的训练面临一个独特的优化挑战：由于路由决策的稀疏性（每个输入只激活 $K'$ 个专家），某些专家如果初始时被选中的概率较低，就很难获得足够的梯度信号来改进其门控权重，从而长期被冷落。这种正反馈机制可能导致少数专家主导路由决策，而多数专家几乎不被激活，形成所谓的"专家坍缩"（Expert Collapse）现象。数学上，这种不平衡可以用专家分配概率的方差来量化：
$$\text{Var}(\mathbf{\pi}) = \frac{1}{K} \sum_{i=1}^{K} (\pi_i - \bar{\pi})^2$$
其中 $\pi_i = \mathbb{P}(I_i = 1)$ 是专家 $i$ 被激活的边际概率，$\bar{\pi} = K'/K$ 是平均分配概率。在理想的均衡状态下，所有 $\pi_i$ 相等，方差为零；在专家坍缩状态下，少数专家的 $\pi_i$ 接近 $K'$，多数专家的 $\pi_i$ 接近零，方差很大。
噪声加入的核心思想是通过在门控得分中注入随机性来打破这种正反馈循环。设原始门控得分为 $\mathbf{s}(\mathbf{x}) = \mathbf{W}\mathbf{x} + \mathbf{b}$，则带噪声的门控得分为：
$$\tilde{\mathbf{s}}(\mathbf{x}) = \mathbf{s}(\mathbf{x}) + \boldsymbol{\epsilon}(\mathbf{x})$$
其中 $\boldsymbol{\epsilon}(\mathbf{x}) = ( \epsilon_1(\mathbf{x}), \epsilon_2(\mathbf{x}), \ldots, \epsilon_K(\mathbf{x}) )$ 是噪声向量。常用的噪声分布是高斯分布：
$$\epsilon_i(\mathbf{x}) \sim \mathcal{N}(0, \sigma^2)$$
其中 $\sigma$ 是噪声的标准差。为了使噪声幅度适应输入的尺度，通常使用输入依赖的归一化噪声：
$$\epsilon_i(\mathbf{x}) \sim \mathcal{N}\left(0, \left(\frac{\text{softplus}(\mathbf{w}_\sigma^\top \mathbf{x} + b_\sigma)}{\text{平均得分}}\right)^2\right)$$
这种归一化确保了噪声的标准差与输入的门控得分成正比，避免了噪声在某些输入上主导决策而在其他输入上可以忽略的问题。
从优化的角度看，噪声加入相当于在门控网络中引入了正则化项。设原始损失为 $\mathcal{L}(\mathbf{x})$，加入噪声后的期望损失为：
$$\tilde{\mathcal{L}}(\mathbf{x}) = \mathbb{E}_{\boldsymbol{\epsilon} \sim p(\cdot|\mathbf{x})} [\mathcal{L}(\mathbf{x} | \boldsymbol{\epsilon})]$$
这个期望损失对门控网络参数 $\mathbf{W}$ 的梯度为：
$$\nabla_{\mathbf{W}} \tilde{\mathcal{L}} = \mathbb{E}_{\boldsymbol{\epsilon}} \left[ \nabla_{\mathbf{W}} \mathcal{L} + \nabla_{\boldsymbol{\epsilon}} \mathcal{L} \cdot \nabla_{\mathbf{W}} \log p(\boldsymbol{\epsilon} | \mathbf{x}) \right]$$
第二项是Score Function梯度估计的变分梯度，它鼓励门控网络在噪声较大时（即某些专家的得分接近边界时）增加探索，从而促进专家分配的多样性。
噪声加入仅在训练阶段使用，推理时需要关闭以获得确定性的路由决策。数学上，这意味着门控函数在训练和推理时有所不同：
$$G_{\text{train}}(\mathbf{x}) = \text{TopK}(\text{Softmax}(\mathbf{W}\mathbf{x} + \mathbf{b} + \boldsymbol{\epsilon}))$$
$$G_{\text{inference}}(\mathbf{x}) = \text{TopK}(\text{Softmax}(\mathbf{W}\mathbf{x} + \mathbf{b}))$$
这种训练-推理不对称性要求实现中仔细管理噪声的开关状态。
噪声标准差 $\sigma$ 是一个重要的超参数，它控制着探索与利用之间的权衡。如果 $\sigma$ 太大，噪声会主导门控信号，使得专家分配变得近乎随机，MoE退化为随机混合专家（Random Mixture of Experts），无法学习到有意义的专业化分工。如果 $\sigma$ 太小，噪声的调节作用有限，模型可能仍然陷入负载不均衡。实践中，$\sigma$ 通常设置为可学习的参数或使用退火策略：在训练初期使用较大的噪声促进探索，随着训练进行逐渐减小噪声以收敛到稳定的分配。数学上，退火策略可以表示为：
$$\sigma(t) = \sigma_0 \cdot \exp(-t / \tau)$$
其中 $t$ 是训练步数，$\sigma_0$ 是初始噪声标准差，$\tau$ 是退火时间常数。
负载均衡不仅依赖于噪声加入，通常还需要显式的辅助损失函数来正则化。设专家 $i$ 在当前批次中的分配比例为：

$$\pi_i^{\text{batch}} = \frac{1}{|\mathcal{B}|} \sum_{\mathbf{x} \in \mathcal{B}} \mathbb{I}(i \in S(\mathbf{x}))$$
其中 $\mathcal{B}$ 是当前批次，$\mathbb{I}$ 是指示函数。理想的负载均衡要求 $\pi_i^{\text{batch}} \approx 1/K$ 对所有 $i$ 成立。辅助损失函数可以定义为分配比例与均匀分布的偏离程度：
$$\mathcal{L}_{\text{balance}} = K \cdot \sum_{i=1}^{K} \pi_i^{\text{batch}} \cdot \log(K \cdot \pi_i^{\text{batch}})$$
这个损失在 $\pi_i^{\text{batch}} = 1/K$ 时最小（值为0），在分配不均衡时增大。将 $\mathcal{L}_{\text{balance}}$ 作为辅助损失加入总损失函数，可以引导门控网络学习更均衡的专家分配策略。
另一种常用的负载均衡损失是平方偏差损失：
$$\mathcal{L}_{\text{balance}}^{\text{squared}} = \sum_{i=1}^{K} \left( \pi_i^{\text{batch}} - \frac{1}{K} \right)^2$$
这种损失函数对极端不均衡的惩罚更大，有利于防止少数专家被过度使用。
在实际训练中，负载均衡损失通常乘以一个权重系数 $\lambda$ 后与主损失（如交叉熵损失）相加：
$$\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{main}} + \lambda \cdot \mathcal{L}_{\text{balance}}$$
权重 $\lambda$ 的选择需要在负载均衡和主任务性能之间取得平衡：$\lambda$ 太小，负载均衡效果不明显；$\lambda$ 太大，可能影响主任务的优化。通常的做法是在训练过程中动态调整 $\lambda$，例如在早期使用较大的 $\lambda$ 促进专家分化，在后期减小 $\lambda$ 让模型专注于主任务优化。