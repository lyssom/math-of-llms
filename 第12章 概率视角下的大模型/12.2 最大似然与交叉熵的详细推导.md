## 12.2.1 最大似然估计的数学原理

最大似然估计（Maximum Likelihood Estimation, MLE）是深度学习中参数学习的核心方法，它通过最大化观测数据的似然函数来寻找最优参数。

### 似然函数的数学定义

对于一个参数化概率模型$p_{\theta}(\mathbf{x})$，给定观测数据集$\mathcal{D} = \{\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \ldots, \mathbf{x}^{(N)}\}$，似然函数定义为：

**定义 12.2.1** （似然函数）  
给定数据集$\mathcal{D}$，参数$\theta$的似然函数为：
$$
\mathcal{L}(\theta; \mathcal{D}) = \prod_{i=1}^{N} p_{\theta}(\mathbf{x}^{(i)})
$$
对数似然函数为： 
$$
\ell(\theta; \mathcal{D}) = \log \mathcal{L}(\theta; \mathcal{D}) = \sum_{i=1}^{N} \log p_{\theta}(\mathbf{x}^{(i)})
$$
**引理 12.2.1** （对数似然的单调性）  
对数变换是单调递增函数，因此：  
$$
\arg\max_{\theta} \mathcal{L}(\theta; \mathcal{D}) = \arg\max_{\theta} \ell(\theta; \mathcal{D})
$$
**证明**：由于$⁡\log$函数在$(0, +\infty)$上单调递增，对于任意$\theta_1, \theta_2$，如果$\mathcal{L}(\theta_1; \mathcal{D}) > \mathcal{L}(\theta_2; \mathcal{D})$，则 $\log \mathcal{L}(\theta_1; \mathcal{D}) > \log \mathcal{L}(\theta_2; \mathcal{D})$。
### 最大似然估计的存在性条件

**定理 12.2.1** （MLE的存在性和唯一性条件）  
在正则条件下，最大似然估计具有以下性质：

1.**存在性**：如果参数空间$\Theta$是紧致的，且似然函数$\mathcal{L}(\theta; \mathcal{D})$关于$\theta$连续，则MLE存在

2.**唯一性**：如果似然函数是严格凹的，则MLE唯一

**证明框架**：

- 紧致性确保连续函数在紧致集上达到最大值
- 严格凹性确保全局最大值唯一

### 大模型中的似然函数形式

对于自回归语言模型，序列的联合概率分布为：
$$
\mathcal{L}(\theta; \mathcal{D}) = \prod_{t=1}^{T} p_{\theta}(x_t | \mathbf{x}_{<t})
$$
对数似然为：  
$$
\ell(\theta; \mathcal{D}) = \sum_{t=1}^{T} \log p_{\theta}(x_t | \mathbf{x}_{<t})
$$
## 12.2.2 交叉熵的数学推导

### 信息论基础

**定义 12.2.2** （信息熵）  
对于离散随机变量$X$，其信息熵定义为：  
$H(X) = -\sum_{x} p(x) \log p(x)$

**定义 12.2.3** （KL散度）  
两个概率分布$p$和$q$之间的KL散度定义为：  
$$D_{KL}(p||q) = \sum_{x} p(x) \log \frac{p(x)}{q(x)}$$​**引理 12.2.2** （KL散度的非负性）  
对于任意两个概率分布$p$和$q$，有$D_{KL}(p||q) \geq 0$，当且仅当$p = q$时取等号。

**证明**：使用Jensen不等式
$$
D_{KL}(p||q) = \mathbb{E}_p\left[\log \frac{p(X)}{q(X)}\right] = -\mathbb{E}_p\left[\log \frac{q(X)}{p(X)}\right]
$$
$$
\geq -\log \mathbb{E}_p\left[\frac{q(X)}{p(X)}\right] = -\log \sum_{x} p(x) \frac{q(x)}{p(x)} = -\log 1 = 0
$$
### 交叉熵的推导

**定义 12.2.4** （交叉熵）  
两个概率分布$p$和$q$的交叉熵定义为：
$$
H(p,q) = -\sum_{x} p(x) \log q(x)
$$
**定理 12.2.2** （交叉熵与KL散度的关系）  
交叉熵与KL散度满足以下关系：  
$$H(p,q) = H(p) + D_{KL}(p||q)$$
**证明**：
$$
\begin{align}
H(p,q) &= -\sum_{x} p(x) \log q(x) \\ &= -\sum_{x} p(x) \log \left(p(x) \frac{q(x)}{p(x)}\right) \\ &= -\sum_{x} p(x) \left[\log p(x) + \log \frac{q(x)}{p(x)}\right] \\ &= -\sum_{x} p(x) \log p(x) - \sum_{x} p(x) \log \frac{q(x)}{p(x)} \\ &= H(p) + D_{KL}(p||q) \end{align}$$
### 最大似然与交叉熵的等价性 
**定理 12.2.3** （MLE与交叉熵的等价性） 对于给定的真实分布 $p_{\text{data}}$ 和模型分布 $p_{\theta}$，最大化对数似然等价于最小化交叉熵： $$\arg\max_{\theta} \mathbb{E}_{p_{\text{data}}}[\log p_{\theta}(X)] = \arg\min_{\theta} H(p_{\text{data}}, p_{\theta})$$ **证明**： 最大化对数似然： $$\max_{\theta} \mathbb{E}_{p_{\text{data}}}[\log p_{\theta}(X)]$$ 等价于最小化其负值： $$\min_{\theta} -\mathbb{E}_{p_{\text{data}}}[\log p_{\theta}(X)] = \min_{\theta} H(p_{\text{data}}, p_{\theta})$$ **推论 12.2.1** （最优性条件） 在最优参数 $\theta^*$ 处，有： $$\mathbb{E}_{p_{\text{data}}[\nabla_{\theta} \log p_{\theta}(X)]|_{\theta = \theta^*}} = 0$$
## 12.2.3 梯度计算与优化
### 似然梯度的数学表达 
**定理 12.2.4** （score函数与似然梯度） 对数似然的梯度为： $$\nabla_{\theta} \ell(\theta; \mathcal{D}) = \sum_{i=1}^{N} \nabla_{\theta} \log p_{\theta}(\mathbf{x}^{(i)})$$ 其中 $\nabla_{\theta} \log p_{\theta}(\mathbf{x})$ 称为score函数。 
### Fisher信息矩阵 
**定义 12.2.5** （Fisher信息矩阵） Fisher信息矩阵定义为score函数的协方差矩阵： $$\mathcal{I}(\theta) = \mathbb{E}_{p_{\theta}}\left[\nabla_{\theta} \log p_{\theta}(X) \nabla_{\theta} \log p_{\theta}(X)^T\right]$$ **引理 12.2.3** （Fisher信息的等价形式） 在正则条件下： $$\mathcal{I}(\theta) = -\mathbb{E}_{p_{\theta}}[\nabla_{\theta}^2 \log p_{\theta}(X)]$$ **证明**：通过泰勒展开和期望的线性性质可得。
## 12.2.4 在深度学习中的实现
### 负对数似然损失函数 
在深度学习中，交叉熵损失函数通常实现为负对数似然： $$\mathcal{L}_{\text{CE}}(\theta) = -\frac{1}{N} \sum_{i=1}^{N} \sum_{c=1}^{C} y_i^{(c)} \log \hat{y}_i^{(c)}$$其中： - $y_i^{(c)}$ 是第 $i$ 个样本的第 $c$ 类真实标签（one-hot编码） - $\hat{y}_i^{(c)} = p_{\theta}(y=c | \mathbf{x}_i)$ 是模型预测概率 
### 数值稳定性考虑 
**引理 12.2.4** （log-sum-exp技巧） 为避免数值下溢，常使用log-sum-exp技巧： $$\log \sum_{i=1}^{n} \exp(z_i) = z_{\max} + \log \sum_{i=1}^{n} \exp(z_i - z_{\max})$$ 其中 $z_{\max} = \max_i z_i$。 
### 12.2.5 理论性质分析 
### 偏差-方差权衡 
**定理 12.2.5** （MSE的偏差-方差分解） 对于估计量 $\hat{\theta}$，均方误差可分解为： $$\mathbb{E}[(\hat{\theta} - \theta)^2] = \text{Bias}(\hat{\theta})^2 + \text{Var}(\hat{\theta})$$ 其中： - $\text{Bias}(\hat{\theta}) = \mathbb{E}[\hat{\theta}] - \theta$ - $\text{Var}(\hat{\theta}) = \mathbb{E}[(\hat{\theta} - \mathbb{E}[\hat{\theta}])^2]$ 
### 一致性和渐近正态性 
**定理 12.2.6** （MLE的一致性和渐近正态性） 在正则条件下：
1. **一致性**：$\hat{\theta}_{\text{MLE}} \xrightarrow{p} \theta_0$ 当 $N \to \infty$ 
2. **渐近正态性**：$\sqrt{N}(\hat{\theta}_{\text{MLE}} - \theta_0) \xrightarrow{d} \mathcal{N}(0, \mathcal{I}(\theta_0)^{-1})$ 
## 12.2.6 与信息论的深层联系
### 互信息的视角 
**定义 12.2.6** （互信息） 随机变量 $X$ 和 $Y$ 之间的互信息定义为： $$I(X;Y) = H(X) - H(X|Y)$$
### 最小描述长度原理 
**引理 12.2.5** （MDL原理） 模型复杂度与似然之间的权衡： $$\text{MDL}(\theta) = -\log p_{\theta}(\mathcal{D}) + \frac{|\theta|}{2} \log N$$这体现了奥卡姆剃刀原理：简单性与拟合度的平衡。
## 12.2.7 实际应用中的考虑 
### 批量大小对梯度估计的影响 
**定理 12.2.7** （随机梯度估计的方差） 使用批量大小为 $B$ 的随机梯度估计方差： $$\text{Var}[\hat{\nabla}_{\theta} \ell] = \frac{1}{B} \left(\mathbb{E}[\|\nabla_{\theta} \ell\|^2] - \|\mathbb{E}[\nabla_{\theta} \ell]\|^2\right)$$
### 学习率调度的理论指导 
基于Fisher信息的自适应学习率： $$\eta_t = \frac{\eta_0}{\sqrt{\mathcal{I}(\theta_t)}}$$ 
这确保在不同参数方向上的步长与信息量成反比。 
## 12.2.8 总结 
最大似然估计与交叉熵是深度学习的理论基础，它们建立了概率建模、优化算法和信息论之间的深层联系。从数学角度看： 
1. **等价性**：MLE与最小化交叉熵在统计意义上等价 
2. **几何解释**：KL散度度量了概率分布之间的差异 
3. **优化性质**：score函数提供了有效的梯度信息 
4. **理论保证**：在正则条件下，MLE具有一致性和渐近最优性 这些数学原理不仅指导了深度学习算法的设计，也为我们理解模型的泛化能力和优化过程提供了理论框架。在大模型时代，这些经典理论仍然发挥着核心作用，为模型的训练和评估提供坚实的数学基础。