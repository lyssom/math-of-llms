## 10.2 最大似然与交叉熵的详细推导
### 10.2.1 最大似然估计的数学原理
最大似然估计（Maximum Likelihood Estimation, MLE）是深度学习中参数学习的核心方法，它通过最大化观测数据的似然函数来寻找最优参数。
对于一个参数化概率模型$p_{\theta}(\mathbf{x})$，给定观测数据集$\mathcal{D} = \{\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \ldots, \mathbf{x}^{(N)}\}$，似然函数定义为：
**定义 10.2.1** （似然函数）  
给定数据集$\mathcal{D}$，参数$\theta$的似然函数为：
$$
\mathcal{L}(\theta; \mathcal{D}) = \prod_{i=1}^{N} p_{\theta}(\mathbf{x}^{(i)})\tag{10.2.1}
$$
对数似然函数为： 
$$
\ell(\theta; \mathcal{D}) = \log \mathcal{L}(\theta; \mathcal{D}) = \sum_{i=1}^{N} \log p_{\theta}(\mathbf{x}^{(i)})\tag{10.2.2}
$$
对数变换是单调递增函数，因此：  
$$
\arg\max_{\theta} \mathcal{L}(\theta; \mathcal{D}) = \arg\max_{\theta} \ell(\theta; \mathcal{D})\tag{10.2.3}
$$
**证明**：由于$⁡\log$函数在$(0, +\infty)$上单调递增，对于任意$\theta_1, \theta_2$，如果$\mathcal{L}(\theta_1; \mathcal{D}) > \mathcal{L}(\theta_2; \mathcal{D})$，则 $\log \mathcal{L}(\theta_1; \mathcal{D}) > \log \mathcal{L}(\theta_2; \mathcal{D})$。
**定理 10.2.1** （MLE的存在性和唯一性条件）  
在正则条件下，最大似然估计具有以下性质：
1.**存在性**：如果参数空间$\Theta$是紧致的，且似然函数$\mathcal{L}(\theta; \mathcal{D})$关于$\theta$连续，则MLE存在
2.**唯一性**：如果似然函数是严格凹的，则MLE唯一
**证明框架**：
- 紧致性确保连续函数在紧致集上达到最大值
- 严格凹性确保全局最大值唯一
对于自回归语言模型，序列的联合概率分布为：
$$
\mathcal{L}(\theta; \mathcal{D}) = \prod_{t=1}^{T} p_{\theta}(x_t | \mathbf{x}_{<t})\tag{10.2.4}
$$
对数似然为：  
$$
\ell(\theta; \mathcal{D}) = \sum_{t=1}^{T} \log p_{\theta}(x_t | \mathbf{x}_{<t})\tag{10.2.5}
$$

### 10.2.2 交叉熵的数学推导
**定义 10.2.2** 对于离散随机变量$X$，其信息熵定义为：  $H(X) = -\sum_{x} p(x) \log p(x)$
**定义 10.2.3** 两个概率分布$p$和$q$之间的KL散度定义为：  
$$D_{KL}(p||q) = \sum_{x} p(x) \log \frac{p(x)}{q(x)}\tag{10.2.6}$$
对于任意两个概率分布$p$和$q$，有$D_{KL}(p||q) \geq 0$，当且仅当$p = q$时取等号。
**证明**：使用Jensen不等式
$$
\begin{align*}
D_{KL}(p||q) & = \mathbb{E}_p\left[\log \frac{p(X)}{q(X)}\right] \\& = -\mathbb{E}_p\left[\log \frac{q(X)}{p(X)}\right]
\geq -\log \mathbb{E}_p\left[\frac{q(X)}{p(X)}\right] \\&= -\log \sum_{x} p(x) \frac{q(x)}{p(x)} = -\log 1 = 0\tag{10.2.7}
\end{align*}
$$

**定义 10.2.4** 两个概率分布$p$和$q$的交叉熵定义为：
$$
H(p,q) = -\sum_{x} p(x) \log q(x)\tag{10.2.8}
$$
**定理 10.2.2** 交叉熵与KL散度满足以下关系：  
$$H(p,q) = H(p) + D_{KL}(p||q)\tag{10.2.9}$$
**证明**：
$$
\begin{align*}
H(p,q) &= -\sum_{x} p(x) \log q(x) \\ &= -\sum_{x} p(x) \log \left(p(x) \frac{q(x)}{p(x)}\right) \\ &= -\sum_{x} p(x) \left[\log p(x) + \log \frac{q(x)}{p(x)}\right] \\ &= -\sum_{x} p(x) \log p(x) - \sum_{x} p(x) \log \frac{q(x)}{p(x)} \\ &= H(p) + D_{KL}(p||q) \tag{10.2.10}\end{align*}$$
**定理 10.2.3** 对于给定的真实分布 $p_{\text{data}}$ 和模型分布 $p_{\theta}$，最大化对数似然等价于最小化交叉熵： $$\arg\max_{\theta} \mathbb{E}_{p_{\text{data}}}[\log p_{\theta}(X)] = \arg\min_{\theta} H(p_{\text{data}}, p_{\theta})\tag{10.2.11}$$
**证明**： 最大化对数似然： $$\max_{\theta} \mathbb{E}_{p_{\text{data}}}[\log p_{\theta}(X)]\tag{10.2.12}$$
等价于最小化其负值： $$\min_{\theta} -\mathbb{E}_{p_{\text{data}}}[\log p_{\theta}(X)] = \min_{\theta} H(p_{\text{data}}, p_{\theta})\tag{10.2.13}$$在最优参数 $\theta^*$ 处，有： $$\mathbb{E}_{p_{\text{data}}[\nabla_{\theta} \log p_{\theta}(X)]|_{\theta = \theta^*}} = 0\tag{10.2.14}$$

### 10.2.3 梯度计算与优化
**定理 10.2.4** 对数似然的梯度为： $$\nabla_{\theta} \ell(\theta; \mathcal{D}) = \sum_{i=1}^{N} \nabla_{\theta} \log p_{\theta}(\mathbf{x}^{(i)})\tag{10.2.15}$$
其中 $\nabla_{\theta} \log p_{\theta}(\mathbf{x})$ 称为score函数。 
**定义 10.2.5** Fisher信息矩阵定义为score函数的协方差矩阵： $$\mathcal{I}(\theta) = \mathbb{E}_{p_{\theta}}\left[\nabla_{\theta} \log p_{\theta}(X) \nabla_{\theta} \log p_{\theta}(X)^T\right]\tag{10.2.16}$$Fisher信息的等价形式在正则条件下： $$\mathcal{I}(\theta) = -\mathbb{E}_{p_{\theta}}[\nabla_{\theta}^2 \log p_{\theta}(X)]\tag{10.2.17}$$
**证明**：通过泰勒展开和期望的线性性质可得。

### 10.2.4 在深度学习中的实现
在深度学习中，交叉熵损失函数通常实现为负对数似然： $$\mathcal{L}_{\text{CE}}(\theta) = -\frac{1}{N} \sum_{i=1}^{N} \sum_{c=1}^{C} y_i^{(c)} \log \hat{y}_i^{(c)}\tag{10.2.18}$$其中： - $y_i^{(c)}$ 是第 $i$ 个样本的第 $c$ 类真实标签（one-hot编码） - $\hat{y}_i^{(c)} = p_{\theta}(y=c | \mathbf{x}_i)$ 是模型预测概率 
为避免数值下溢，常使用log-sum-exp技巧： $$\log \sum_{i=1}^{n} \exp(z_i) = z_{\max} + \log \sum_{i=1}^{n} \exp(z_i - z_{\max})\tag{10.2.19}$$
其中 $z_{\max} = \max_i z_i$。 

### 10.2.5 理论性质分析 
**定理 10.2.5**  对于估计量 $\hat{\theta}$，均方误差可分解为： $$\mathbb{E}[(\hat{\theta} - \theta)^2] = \text{Bias}(\hat{\theta})^2 + \text{Var}(\hat{\theta})\tag{10.2.20}$$
其中： - $\text{Bias}(\hat{\theta}) = \mathbb{E}[\hat{\theta}] - \theta$ - $\text{Var}(\hat{\theta}) = \mathbb{E}[(\hat{\theta} - \mathbb{E}[\hat{\theta}])^2]$ 
**定理 10.2.6** MLE的一致性和渐近正态性，在正则条件下：
1. **一致性**：$\hat{\theta}_{\text{MLE}} \xrightarrow{p} \theta_0$ 当 $N \to \infty$ 
2. **渐近正态性**：$\sqrt{N}(\hat{\theta}_{\text{MLE}} - \theta_0) \xrightarrow{d} \mathcal{N}(0, \mathcal{I}(\theta_0)^{-1})$ 

### 10.2.6 与信息论的深层联系
**定义 10.2.6**  随机变量 $X$ 和 $Y$ 之间的互信息定义为： $$I(X;Y) = H(X) - H(X|Y)\tag{10.2.21}$$
模型复杂度与似然之间的权衡： $$\text{MDL}(\theta) = -\log p_{\theta}(\mathcal{D}) + \frac{|\theta|}{2} \log N\tag{10.2.22}$$这体现了奥卡姆剃刀原理：简单性与拟合度的平衡。

### 10.2.7 实际应用中的考虑 
**定理 10.2.7** 使用批量大小为 $B$ 的随机梯度估计方差： $$\text{Var}[\hat{\nabla}_{\theta} \ell] = \frac{1}{B} \left(\mathbb{E}[\|\nabla_{\theta} \ell\|^2] - \|\mathbb{E}[\nabla_{\theta} \ell]\|^2\right)\tag{10.2.23}$$
基于Fisher信息的自适应学习率： $$\eta_t = \frac{\eta_0}{\sqrt{\mathcal{I}(\theta_t)}}\tag{10.2.24}$$ 
这确保在不同参数方向上的步长与信息量成反比。 

### 10.2.8 本节小结
最大似然估计与交叉熵是深度学习的理论基础，它们建立了概率建模、优化算法和信息论之间的深层联系。从数学角度看： 
1. **等价性**：MLE与最小化交叉熵在统计意义上等价 
2. **几何解释**：KL散度度量了概率分布之间的差异 
3. **优化性质**：score函数提供了有效的梯度信息 
4. **理论保证**：在正则条件下，MLE具有一致性和渐近最优性 这些数学原理不仅指导了深度学习算法的设计，也为我们理解模型的泛化能力和优化过程提供了理论框架。在大模型时代，这些经典理论仍然发挥着核心作用，为模型的训练和评估提供坚实的数学基础。