## 6.4 Rotary Position Embedding：群表示与旋转不变性

位置编码是Transformer架构中最具数学美感的设计之一。从2017年Vaswani等人提出的原始正弦位置编码，到2021年前后RoPE（Rotary Position Embedding）的诞生，这一领域经历了从启发式设计到数学最优解的深刻转变。RoPE不仅仅是一种新的位置编码技术，更是对位置信息与注意力机制关系的根本性重新思考。本节将从数学本质出发，系统性地剖析RoPE的设计哲学、理论证明、工程实现及其在现代大语言模型中的核心地位。

### 6.4.1 位置编码的本质问题与RoPE的范式转换

自注意力机制的核心运算是Query-Key内积：

$$
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^\top}{\sqrt{d_k}}\right)V \tag{6.4.1}
$$

这一公式在形式上具有完美的对称性，它对所有输入token一视同仁，不区分它们的先后顺序。表面上看，这是自注意力机制的优势：它能够并行处理序列中的所有位置，最大化计算效率。然而，这种并行性恰恰是其致命缺陷的根源。在自然语言中，词语的顺序承载着至关重要的语义信息。"狗咬人"与"人咬狗"包含完全相同的词汇，却表达着截然相反的事实；"我喜欢学习"与"学习喜欢我"虽然词汇相同，却因主客关系的颠倒而意义迥异。位置编码的使命，就是在保持自注意力并行计算优势的同时，将序列的顺序信息注入到模型之中。

位置编码问题可以形式化地表述为：我们需要构造一个位置感知的表示函数$f(x_i, i)$，其中$x_i$是第$i$个位置的输入嵌入，$i$是绝对位置。这个函数应当满足的核心要求是平移等变性，相对位置应该决定注意力权重。具体而言，对于任意平移量$t$，有：

$$
\langle f(q_i, i), f(k_j, j) \rangle = \langle f(q_{i+t}, i+t), f(k_{j+t}, j+t) \rangle \tag{6.4.2}
$$

这意味着两个token之间的注意力分数只取决于它们的相对位置$j-i$，而与它们在序列中的绝对位置无关。这一性质对于语言模型捕捉局部模式至关重要，因为语言中的许多规律具有位置平移不变性。

Vaswani等人提出的正弦位置编码是最早的解决方案，其数学形式为：

$$
\begin{align*}
PE_{(pos, 2k)} = \sin\left(\frac{pos}{10000^{2k/d}}\right), \\\quad PE_{(pos, 2k+1)} = \cos\left(\frac{pos}{10000^{2k/d}}\right) \tag{6.4.3}
\end{align*}
$$

然而，正弦位置编码存在根本性的数学缺陷。它采用的是加性注入方式$x_i^{\text{abs}} = x_i + PE(i)$，这种加法操作虽然简单直接，却与自注意力的核心运算（内积）存在结构性冲突。当我们计算两个加了位置编码的向量的内积时：

$$
\begin{align*}
& \langle x_i + PE(i), x_j + PE(j) \rangle = \\&  \langle x_i, x_j \rangle + \langle x_i, PE(j) \rangle + \langle PE(i), x_j \rangle + \langle PE(i), PE(j) \rangle \tag{6.4.4}
\end{align*}
$$

等式右边的第二和第三项是内容与位置的交叉项，它们打破了注意力机制本应具有的平移等变性。绝对位置$i$和$j$分别出现在不同的项中，导致内积同时受到两个绝对位置的影响，而非仅由它们的差$j-i$决定。正因如此，后续的研究者开始探索乘法式的位置编码方式，而RoPE正是这一探索的集大成之作。

### 6.4.2 复数表示下的旋转算子

RoPE的洞察始于一个看似简单却极其深刻的问题：位置信息应该以什么方式编码到向量中？正弦位置编码将位置编码为幅度，不同位置对应不同的数值。RoPE则提出了一个根本不同的视角：位置应该编码为相位。

为了理解这一点，让我们首先建立复数与向量之间的对应关系。在RoPE的框架中，每个$d$维的嵌入向量被成对地组织为$d/2$个复数：

$$
(x_{2k}, x_{2k+1}) \longleftrightarrow z_k = x_{2k} + i x_{2k+1} \tag{6.4.5}
$$

这里$i$是虚数单位，满足$i^2 = -1$。这种表示并非数学游戏，而是具有深刻的物理直觉：复数的实部和虚部可以看作是在二维平面上的坐标，而复数的模长代表向量的长度，相角代表向量的方向。

将位置编码问题置于复数框架下后，RoPE提出了关键性的设计：不是为每个位置分配一个固定的数值，而是让每个位置对应一个旋转操作。具体而言，对于位置$pos$，我们定义：

$$
z_k(pos) = z_k \cdot e^{i\theta_k \cdot pos} \tag{6.4.6}
$$

其中旋转角度$\theta_k$随维度索引$k$变化：

$$
\theta_k = 10000^{-2k/d} \tag{6.4.7}
$$

这个公式中的底数10000和指数$-2k/d$共同决定了不同维度上的旋转频率。低维度（$k$较小）对应低频旋转，能够捕捉长距离的位置依赖；高维度（$k$较大）对应高频旋转，能够区分相邻位置。

为了更直观地理解RoPE的运作机制，考虑一个简化的二维例子。假设我们有一个二维向量$v = (v_x, v_y)$，它对应复数$z = v_x + i v_y$。当我们在位置$pos$应用RoPE时，这个向量被旋转了一个角度$\theta \cdot pos$：

$$
z^{\text{RoPE}}(pos) = z \cdot e^{i\theta \cdot pos} = z(\cos(\theta \cdot pos) + i \sin(\theta \cdot pos)) \tag{6.4.8}
$$

在几何上，这意味着向量$v$绕原点逆时针旋转了$\theta \cdot pos$弧度。旋转后的向量为：

$$
v^{\text{RoPE}}(pos) = \begin{pmatrix} v_x \cos(\theta \cdot pos) - v_y \sin(\theta \cdot pos) \\ v_x \sin(\theta \cdot pos) + v_y \cos(\theta \cdot pos) \end{pmatrix} \tag{6.4.9}
$$

关键的理解在于：旋转操作不改变向量的长度，只改变它的方向。向量的模长$|v^{\text{RoPE}}| = |v|$对所有位置都保持不变。这意味着RoPE注入位置信息的方式是温和的，它不改变向量的总体强度，只重新定向它在高维空间中的指向。

虽然复数提供了优雅的数学语言，但实际的神经网络实现必须在实数域中进行。复数乘法可以自然地表示为二维旋转矩阵的乘法。给定角度$\theta$，对应的旋转矩阵为：

$$
R(\theta) = \begin{pmatrix} \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta \end{pmatrix} \tag{6.4.10}
$$

验证复数乘法与矩阵乘法的对应关系。复数$z = a + ib$乘以$e^{i\theta} = \cos\theta + i\sin\theta$得到：

$$
z \cdot e^{i\theta} = (a\cos\theta - b\sin\theta) + i(a\sin\theta + b\cos\theta) \tag{6.4.11}
$$

用矩阵形式表示为两者完全一致。因此，对于完整的$d$维向量（假设$d$为偶数），RoPE操作由$d/2$个独立的二维旋转组成，这些旋转组合成一个块对角矩阵：

$$
R(pos) = \mathrm{diag}\Big(R(\theta_1 \cdot pos), R(\theta_2 \cdot pos), \dots, R(\theta_{d/2} \cdot pos)\Big) \tag{6.4.12}
$$

其中$\theta_k = 10000^{-2k/d}$。每个块$R(\theta_k \cdot pos)$是一个$2 \times 2$的旋转矩阵，负责处理对应的一对维度。

### 6.4.3 SO(2)群与位置平移的数学结构

从抽象代数的角度看，RoPE的数学结构可以用群论的语言来描述，这不仅提供了更深刻的理解，也揭示了RoPE与其他位置编码方法的本质区别。

考虑二维平面上的旋转操作。所有旋转操作的集合关于矩阵乘法构成一个群，称为特殊正交群$SO(2)$：

$$
SO(2) = \{R(\theta) \mid \theta \in \mathbb{R}\} \tag{6.4.13}
$$

$SO(2)$的群结构由以下性质刻画：封闭性表明两个旋转的复合仍是一个旋转，即$R(\alpha) R(\beta) = R(\alpha + \beta)$；单位元表明零角度旋转$R(0)$是单位元；逆元表明旋转$R(\theta)$的逆元是反向旋转$R(-\theta)$；结合性表明$(R(\alpha)R(\beta))R(\gamma) = R(\alpha)(R(\beta)R(\gamma))$。

RoPE中使用的群结构是$SO(2)$的$d/2$次直积：

$$
G = SO(2)^{\times d/2} = SO(2) \times SO(2) \times \dots \times SO(2) \tag{6.4.14}
$$

直积群的元素是$d/2$个$SO(2)$元素的元组，运算按分量独立进行。这种结构恰好对应于RoPE的块对角矩阵形式：每个$2 \times 2$的旋转块独立运作，共同构成完整的变换。

群论的核心概念是群作用。在RoPE的语境中，群作用描述了如何将群元素（旋转）应用于位置。具体而言：

$$
\phi: \mathbb{Z} \to G, \quad \phi(pos) = R(pos) \tag{6.4.15}
$$

这个映射满足群同态性质：$\phi(pos_1 + pos_2) = \phi(pos_1) \cdot \phi(pos_2)$，用矩阵语言表达就是$R(pos_1 + pos_2) = R(pos_1) R(pos_2)$，这正是旋转矩阵的可加性。

现在考虑自注意力中的Query-Key内积运算。在群作用的语言下，内积可以看作是一个$G$-等变的运算：

$$
\langle \phi(i)q, \phi(j)k \rangle = \langle q, \phi(j-i)k \rangle \tag{6.4.16}
$$

等式右边只依赖于相对位置$j-i$，这正是平移等变性的群论表述：当我们同时平移两个位置（将$i$变为$i+t$，$j$变为$j+t$），内积的值保持不变。

让我们给出RoPE平移等变性的严格数学证明。设$q_i = R(i)q$、$k_j = R(j)k$为经过RoPE编码的Query和Key向量，则对任意整数平移量$t$，有：

$$
\langle q_{i+t}, k_{j+t} \rangle = \langle q_i, k_j \rangle \tag{6.4.17}
$$

证明利用旋转矩阵的性质直接计算：

$$
\begin{align*}
\langle q_{i+t}, k_{j+t} \rangle &= (R(i+t)q)^\top (R(j+t)k) \\
&= q^\top R(i+t)^\top R(j+t) k \\
&= q^\top R(-(i+t)) R(j+t) k \\
&= q^\top R(-i) R(-t) R(j) R(t) k
\tag{6.4.18}
\end{align*} 
$$

由于$R(-t)R(t) = R(0) = I$（单位矩阵），因此：

$$
\begin{align*}
\langle q_{i+t}, k_{j+t} \rangle &= q^\top R(-i) R(j) k \\
&= (R(i)q)^\top (R(j)k) \\
&= \langle q_i, k_j \rangle
\tag{6.4.19}
\end{align*}
$$

这个证明的关键步骤是利用了旋转矩阵的可交换性（$SO(2)$是阿贝尔群）和正交性$R(\theta)^\top = R(-\theta)$。正是这些代数性质保证了平移等变性的成立。

### 6.4.4 点积中的相对位置信息

RoPE最神奇的性质是：我们从未显式地告诉模型"相对位置是什么"，但模型自发地获得了相对位置感知能力。这并非偶然，而是数学必然。

考虑两个位置$i$和$j$，它们的RoPE编码向量分别为$q_i = R(i)q$和$k_j = R(j)k$，其中$R(\theta)$是角度为$\theta$的旋转矩阵，$q$和$k$是原始的Query和Key向量。现在计算它们的内积：

$$
\langle q_i, k_j \rangle = (R(i)q)^\top (R(j)k) = q^\top R(i)^\top R(j) k \tag{6.4.20}
$$

利用旋转矩阵的正交性$R(\theta)^\top = R(-\theta)$，我们有：

$$
R(i)^\top R(j) = R(-i) R(j) = R(j-i) \tag{6.4.21}
$$

因此：

$$
\langle q_i, k_j \rangle = q^\top R(j-i) k \tag{6.4.22}
$$

这个等式的右边只依赖于$j-i$，即两个位置的相对距离。这意味着，通过简单地让不同位置对应不同的旋转，Query-Key内积自动地只与相对位置有关。我们不需要任何显式的相对位置计算，不需要额外的相对位置偏置，数学的自然结果就是平移等变性。

这是一个值得反复品味的结论。在传统的加性位置编码中，我们试图添加位置信息到内容中，但这种添加是生硬的、有副作用的。在RoPE中，我们通过旋转来标记位置，而内积运算本身就会抵消绝对位置，只留下相对位置信息。这种设计体现了数学的优雅：好的设计不是添加复杂性，而是让复杂性自然涌现。

这个结果是RoPE理论的核心成果。它表明：经过RoPE编码后的Query-Key内积，严格地只依赖于两个位置的相对距离$j-i$，与绝对位置$i$和$j$无关。这是一个极强的数学保证，而非经验性的观察。

值得注意的是，这个结果不依赖于任何可学习的参数。RoPE的位置编码是确定性的、由公式完全指定的。这带来了两个重要优势：第一，位置编码本身不会增加可训练参数的数量，减少了过拟合的风险；第二，位置编码的计算是稳定且可预测的，不会出现训练过程中位置编码漂移的问题。

让我们分析两种编码方式下Query-Key内积的差异。对于正弦位置编码，内积为：

$$
\begin{align*}
&\langle x_i + PE(i), x_j + PE(j) \rangle =\\& \langle x_i, x_j \rangle + \langle x_i, PE(j) \rangle + \langle PE(i), x_j \rangle + \langle PE(i), PE(j) \rangle \tag{6.4.23}
\end{align*}
$$

这个展开式揭示了问题的复杂性：位置信息以三种不同的方式混入内积计算，内容与位置的交叉项以及纯位置项。模型无法简单地忽略位置信息，因为它已经与内容信息纠缠在一起。

对于RoPE编码，内积为$\langle R(i)q, R(j)k \rangle = q^\top R(j-i) k$。这个结果干净得多：内积严格等于原始Query和Key在一个旋转后的向量上的内积，而这个旋转完全由相对位置$j-i$决定。位置信息没有与内容信息混淆，内容向量$q$和$k$保持完整，只有位置相关的旋转介入内积计算。

### 6.4.5 RoPE的外推性质与数学保证

位置编码的外推能力是指给定训练时见过的序列长度，模型能否在推理时处理更长的序列。这是位置编码实用性的重要指标。

正弦位置编码在理论上可以外推到任意长度，因为正弦函数对所有实数都有定义。然而，在实践中，外推性能往往不佳。其原因在于：当序列长度超出训练范围时，模型需要推断未见过的位置编码，这在加性注入的框架下是困难的，因为模型从未学习过如何处理那种位置与内容的新组合。

RoPE的外推能力源于其旋转结构。由于旋转操作是周期性的（周期为$2\pi$），即使位置索引超出了训练范围，旋转角度$\theta_k \cdot pos$也只是落在实数轴的某个位置上，旋转矩阵仍然有定义。更重要的是，RoPE的相对位置内积结构$q^\top R(j-i)k$只依赖于相对位置$j-i$，而相对位置的范围在推理时与训练时是相同的。

从信息论的角度看，RoPE将位置信息编码为相位，而相位是循环的、无界的（角度可以无限增长）。这意味着模型可以自然地处理任意长度的序列，只需要将更长的索引映射到更大的角度，而不需要重新训练或特殊的插值策略。

RoPE公式中频率参数$\theta_k = 10000^{-2k/d}$的选择并非随意，而是经过深思熟虑的设计。首先，$\theta_k$的取值范围是$\theta_1 = 10000^{-2/d}$到$\theta_{d/2} = 10000^{-1}$。当$d$较大（如512或1024）时，$\theta_1$非常接近1，这意味着最低频的维度每个位置只旋转极小的角度，能够区分非常远的位置；而最高频的维度$\theta_{d/2} \approx 0.01$，每个位置的旋转角度较小，但在序列较短时仍能提供有效的位置区分。

频率参数选择10000作为底数，其历史渊源可以追溯到正弦位置编码的原始论文。直觉上，这个数值足够大，使得不同位置的相位在大多数维度上不会过快收敛；同时又足够小，确保位置编码不会过度主导内容信息。从信息论的角度看，这种多频率的设计实现了频谱的全覆盖，低频成分对应长程位置依赖，高频成分对应短程位置依赖。通过让不同维度编码不同频率的位置信息，RoPE能够同时捕捉这两种尺度的位置依赖。

在实际实现中，RoPE的第一步是构建位置索引。给定序列长度$L$和模型维度$d$，我们需要计算每个位置$pos \in \{0, 1, \dots, L-1\}$对应的旋转角度。RoPE的核心公式是$\theta_k = 10000^{-2k/d}$，对于位置$pos$和维度索引$k$，旋转角度为$\theta_k \cdot pos$。因此，完整的位置角度矩阵为：

$$
\Theta = \begin{pmatrix} \theta_0 \cdot 0 & \theta_1 \cdot 0 & \dots & \theta_{d/2-1} \cdot 0 \\ \theta_0 \cdot 1 & \theta_1 \cdot 1 & \dots & \theta_{d/2-1} \cdot 1 \\ \vdots & \vdots & \ddots & \vdots \\ \theta_0 \cdot (L-1) & \theta_1 \cdot (L-1) & \dots & \theta_{d/2-1} \cdot (L-1) \end{pmatrix} \tag{6.4.24}
$$

旋转向量的计算需要遍历每个位置和每个维度，计算旋转矩阵的四个元素并执行矩阵乘法。更高效的实现利用了以下观察：对于每个位置$pos$，我们需要计算$2 \times 2$旋转矩阵$R(\theta_k \cdot pos)$的四个元素。直接计算正弦和余弦函数是昂贵的，但我们可以利用三角恒等式来优化。

对于向量$x = (x_0, x_1, \dots, x_{d-1})$，旋转向量$x^{\text{RoPE}}$的计算为：

$$
x^{\text{RoPE}}_{2k} = x_{2k} \cos(\theta_k \cdot pos) - x_{2k+1} \sin(\theta_k \cdot pos) \tag{6.4.25}
$$

$$
x^{\text{RoPE}}_{2k+1} = x_{2k} \sin(\theta_k \cdot pos) + x_{2k+1} \cos(\theta_k \cdot pos) \tag{6.4.26}
$$

这种实现方式充分利用了现代GPU的向量化计算能力，可以高效地处理大批量的序列。

### 6.4.6 RoPE与主流位置编码的比较

正弦位置编码和RoPE代表了两种截然不同的位置编码范式。正弦位置编码采用的是加性注入的设计哲学，它将位置信息视为一种附加信号，通过向量加法直接叠加到内容嵌入上。这种设计的优势在于简单直观，位置编码就是位置编码，两者相加得到最终表示。然而，这种简单性掩盖了深层次的问题：加法操作破坏了内容向量的原有结构，使得后续的自注意力运算无法干净地分离位置信息和内容信息。

RoPE采用的是乘法变换的设计哲学，它将位置信息编码为一种变换，通过旋转操作来标记位置。旋转操作是线性变换的一种，它保持了向量空间的代数结构，同时改变了向量的方向。这种变换是可逆的、平滑的，并且与后续的内积运算具有良好的兼容性。

从群论角度看，正弦位置编码没有明确的群结构，其位置编码函数只是简单地映射位置到向量。而RoPE建立在$SO(2)$群的旋转操作上，具有完整的代数结构。这种结构保证了平移等变性的严格成立，是数学上的最优解。

2021年Su等人发表RoPE论文后短短几年内，几乎所有主流的大语言模型都采用了RoPE或其变体。这一趋势的背后有多重原因：数学上的优雅性是首要因素，RoPE的平移等变性是严格可证的，而非经验性的；实现上的简洁性是第二个因素，RoPE不需要额外的可学习参数，不需要复杂的插值策略，只需要简单的三角函数计算和逐元素乘法；外推上的鲁棒性是第三个因素，在实际应用中，用户可能需要模型处理比训练时更长的上下文，RoPE的外推能力使得这种需求更容易满足；性能上的竞争力是第四个因素，大量实验表明，RoPE在各种语言建模任务上与或超越其他位置编码方法，同时具有更好的外推性能。

尽管RoPE具有诸多优势，但它并非完美无缺。理解RoPE的局限性对于正确使用它至关重要。绝对位置信息的丢失是一个理论上的局限，严格遵循RoPE的设计，模型只能感知相对位置，无法直接知道一个token在序列中的绝对位置。虽然某些语言现象确实需要绝对位置，但RoPE的相对位置-only特性可能限制了对这类信息的捕捉。长距离衰减问题是一个实践中的挑战，虽然RoPE理论上支持任意长度的外推，但在非常长的序列上，位置编码的质量可能下降。

### 6.4.7 本节小结

本节深入探讨了旋转位置编码的数学原理、设计哲学和工程实践。RoPE的核心思想可以概括为：用群作用把"位置平移"编码成"相位旋转"，使Attention的内积天然等变于相对位移。

从数学角度看，RoPE的精妙之处在于它将位置编码问题转化为旋转群上的问题。通过将每两个维度视为复数平面上的一个点，位置索引对应旋转角度，Query-Key内积就自然地只依赖于相对位置。这种设计没有引入额外的可学习参数，没有破坏注意力机制的代数结构，却在数学上严格保证了平移等变性。$SO(2)$群的代数结构（封闭性、单位元、逆元、结合性）保证了旋转操作的数学一致性，使得平移等变性能够被严格证明。

从工程角度看，RoPE的实现简洁高效，只需要计算三角函数并进行逐元素乘法。它与现有的深度学习框架兼容良好，可以无缝集成到各种模型架构中。RoPE的外推能力使其成为处理长上下文的有力工具，这是其他位置编码方法难以企及的优势。

从历史角度看，RoPE代表了位置编码设计从启发式到数学最优的转变。正弦位置编码虽然简单，但缺乏严格的理论保证；RoPE则建立在坚实的群论基础上，其性质可以被严格证明。这种从经验到理论的发展，标志着位置编码研究的成熟。在未来的大语言模型发展中，位置编码将继续扮演关键角色，理解RoPE的数学本质，将帮助我们更好地改进和发展下一代位置编码技术。